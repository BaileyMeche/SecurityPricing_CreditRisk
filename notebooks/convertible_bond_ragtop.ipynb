{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8d9744",
   "metadata": {},
   "source": [
    "# Convertible Bond Pricing & Option-Market Calibration (ragtop reduced-form)\n",
    "\n",
    "This notebook prepares a report-ready scaffold for analysing a convertible bond structure under a reduced-form jump-to-default framework. Heavy calibration grids and finite-difference (FD) sweeps are intentionally gated so that readers can rerun the expensive blocks later. We focus on conversion and do not model issuer call or put schedules; these could be added via the jump conditions for calls/puts described in Andersen & Buffum’s convertible notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb7ad7",
   "metadata": {},
   "source": [
    "## 0. Setup & notebook controls\n",
    "\n",
    "We collect the required libraries, define runtime toggles, and verify the `ragtop` Black–Scholes API that we use throughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0300d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import ragtop\n",
    "from ragtop.blackscholes import black_scholes as _ragtop_bs_impl\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"axes.labelsize\"] = 11\n",
    "\n",
    "RUN_HEAVY = False      # gate calibration loops and FD grids\n",
    "SAVE_ARTIFACTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "ART_DIR = Path(\"../artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Wrapper to handle ragtop returning either dict or scalar\n",
    "def _extract_price(result):\n",
    "    \"\"\"Extract numeric price from ragtop result (handles dict or scalar).\"\"\"\n",
    "    if isinstance(result, dict):\n",
    "        for key in ['price', 'value', 'option_price']:\n",
    "            if key in result:\n",
    "                return _extract_price(result[key])\n",
    "        for v in result.values():\n",
    "            if isinstance(v, (int, float, np.floating)):\n",
    "                return float(v)\n",
    "        raise ValueError(f\"Cannot extract price from dict: {result}\")\n",
    "    return float(result)\n",
    "\n",
    "def black_scholes(callput, spot, strike, rate, time, sigma, borrow_cost=0.0):\n",
    "    \"\"\"Black-Scholes option pricer (wrapped ragtop).\"\"\"\n",
    "    result = _ragtop_bs_impl(callput, spot, strike, rate, time, sigma, borrow_cost=borrow_cost)\n",
    "    return _extract_price(result)\n",
    "\n",
    "# Sanity check: ragtop Black–Scholes signature matches expectations.\n",
    "_test_px = black_scholes(-1, 625, 612, 0.05, 0.75, 0.62, borrow_cost=0.011)\n",
    "assert abs(_test_px - 113.34) < 1e-2, f\"ragtop black_scholes sanity check failed; got {_test_px}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfca875",
   "metadata": {},
   "source": [
    "## 1. Market data snapshot\n",
    "\n",
    "Risk-free rates are supplied as continuously-compounded spot rates (annualised). We interpolate linearly in maturity to recover $r(t)$, discount factors, and average rates used in the option and convertible pricing blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9bede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049886</td>\n",
       "      <td>0.004208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126598</td>\n",
       "      <td>0.004846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375913</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625228</td>\n",
       "      <td>0.009879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721119</td>\n",
       "      <td>0.010491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.718379</td>\n",
       "      <td>0.010167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time      rate\n",
       "0  0.049886  0.004208\n",
       "1  0.126598  0.004846\n",
       "2  0.375913  0.007778\n",
       "3  0.625228  0.009879\n",
       "4  0.721119  0.010491\n",
       "5  1.718379  0.010167\n",
       "6  5.000000  0.020000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_df = pd.DataFrame(\n",
    "    [\n",
    "        (0.04988584, 0.004208395),\n",
    "        (0.12659817, 0.004846041),\n",
    "        (0.37591324, 0.007777790),\n",
    "        (0.62522831, 0.009878801),\n",
    "        (0.72111872, 0.010491200),\n",
    "        (1.71837900, 0.010167270),\n",
    "        (5.00000000, 0.020000000),\n",
    "    ],\n",
    "    columns=[\"time\", \"rate\"],\n",
    ")\n",
    "curve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_27620\\4202758411.py:24: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return float(np.trapz(rates, knots))\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "_times = curve_df[\"time\"].to_numpy()\n",
    "_rates = curve_df[\"rate\"].to_numpy()\n",
    "_r_interp = interp1d(_times, _rates, kind=\"linear\", fill_value=\"extrapolate\", assume_sorted=True)\n",
    "\n",
    "\n",
    "def r_of(t: float) -> float:\n",
    "    \"\"\"Piecewise-linear spot rate r(t).\"\"\"\n",
    "    return float(_r_interp(np.clip(float(t), 0.0, float(_times[-1]))))\n",
    "\n",
    "\n",
    "def _integral_rate(t: float) -> float:\n",
    "    \"\"\"Integral of r from 0 to t using trapezoidal integration on the linear curve.\"\"\"\n",
    "    t = float(t)\n",
    "    if t <= 0.0:\n",
    "        return 0.0\n",
    "    knots = [0.0]\n",
    "    knots.extend(float(x) for x in _times if x < t)\n",
    "    if knots[-1] != t:\n",
    "        knots.append(t)\n",
    "    knots = np.asarray(knots)\n",
    "    rates = np.array([r_of(k) for k in knots])\n",
    "    return float(np.trapz(rates, knots))\n",
    "\n",
    "\n",
    "def discount_factor(t: float) -> float:\n",
    "    return float(np.exp(-_integral_rate(t)))\n",
    "\n",
    "\n",
    "def average_rate(t: float) -> float:\n",
    "    t = float(t)\n",
    "    return r_of(0.0) if t <= 0.0 else _integral_rate(t) / t\n",
    "\n",
    "\n",
    "# Discount monotonicity sanity check (cheap test kept active).\n",
    "assert discount_factor(2.0) < discount_factor(1.0) < 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021baea6",
   "metadata": {},
   "source": [
    "### Equity, option quotes, and convertible terms\n",
    "\n",
    "All instruments reference the same underlying equity with spot $S_0 = 241.80$ and no dividends. Option maturities are aligned at $T_{\\mathrm{opt}} = 1.72$ years.\n",
    "\n",
    "Convertible recovery inputs assume `RECOVERY_BOND = 0.40` as a fraction-of-notional recovery in default—typical for senior unsecured debt—and `RECOVERY_EQUITY = 0.0` so the equity leg is wiped out. This matches the reduced-form PDE source term $\\lambda R_b N$ described by Andersen & Buffum (2004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ce73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  label  callput      K    mid    bid    ask\n",
       " 0  P230       -1  230.0  52.40  51.35  53.45\n",
       " 1  P150       -1  150.0  19.45  17.90  21.00\n",
       " 2  C370        1  370.0  13.95  13.00  14.90,\n",
       "       category              field       value\n",
       " 0         Spot                 S0   241.80000\n",
       " 1       Option              T_opt     1.72000\n",
       " 2  Convertible           Notional  1000.00000\n",
       " 3  Convertible   Conversion ratio     3.84615\n",
       " 4  Convertible              Tenor     2.00000\n",
       " 5  Convertible    Recovery (bond)     0.40000\n",
       " 6  Convertible  Recovery (equity)     0.00000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0 = 241.80\n",
    "DIVIDEND_YIELD = 0.0\n",
    "T_opt = 1.72\n",
    "\n",
    "option_quotes = pd.DataFrame(\n",
    "    [\n",
    "        (\"P230\", -1, 230.0, 52.40, 51.35, 53.45),\n",
    "        (\"P150\", -1, 150.0, 19.45, 17.90, 21.00),\n",
    "        (\"C370\", +1, 370.0, 13.95, 13.00, 14.90),\n",
    "    ],\n",
    "    columns=[\"label\", \"callput\", \"K\", \"mid\", \"bid\", \"ask\"],\n",
    ")\n",
    "\n",
    "NOTIONAL = 1_000.0\n",
    "CONVERSION_RATIO = 3.84615  # conversion price 260\n",
    "T_cb = 2.0\n",
    "RECOVERY_BOND = 0.40\n",
    "RECOVERY_EQUITY = 0.0\n",
    "BORROW_COST_OPTION = 0.0\n",
    "\n",
    "snapshot_rows = [\n",
    "    (\"Spot\", \"S0\", S0),\n",
    "    (\"Option\", \"T_opt\", T_opt),\n",
    "    (\"Convertible\", \"Notional\", NOTIONAL),\n",
    "    (\"Convertible\", \"Conversion ratio\", CONVERSION_RATIO),\n",
    "    (\"Convertible\", \"Tenor\", T_cb),\n",
    "    (\"Convertible\", \"Recovery (bond)\", RECOVERY_BOND),\n",
    "    (\"Convertible\", \"Recovery (equity)\", RECOVERY_EQUITY),\n",
    "]\n",
    "\n",
    "snapshot_table = pd.DataFrame(snapshot_rows, columns=[\"category\", \"field\", \"value\"])\n",
    "option_quotes, snapshot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b8fec",
   "metadata": {},
   "source": [
    "## 2. Part 1 — Constant-parameter pricing\n",
    "\n",
    "We splice a constant hazard level ($\\lambda = 7.5\\%$) into the equity via a “dividend-like” adjustment and use `ragtop.black_scholes` as the sole pricing and implied-volatility engine. Each option is evaluated twice: first under the default-free Black–Scholes model (borrow_cost = 0) and then with an effective dividend $q_{\\mathrm{eff}} = q + \\lambda$ to mimic jump-to-default risk while preserving put–call parity. This shortcut is only applied to the listed options; the convertible bond itself is valued with the reduced-form PDE that includes the $(r+\\lambda)$ kill term, the $\\lambda R_b N$ recovery source, and the early-conversion obstacle described by Andersen & Buffum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs_price(callput: int, S: float, K: float, T: float, r: float, borrow_cost: float, sigma: float) -> float:\n",
    "    return float(black_scholes(callput, S, K, r, T, sigma, borrow_cost=borrow_cost))\n",
    "\n",
    "\n",
    "def implied_vol_with_ragtop(\n",
    "    callput: int,\n",
    "    S: float,\n",
    "    K: float,\n",
    "    T: float,\n",
    "    r: float,\n",
    "    price: float,\n",
    "    *,\n",
    "    borrow_cost: float = 0.0,\n",
    "    tol: float = 1e-8,\n",
    ") -> float:\n",
    "    \"\"\"Implied volatility via Brent's method on ragtop Black–Scholes.\"\"\"\n",
    "    if T <= 0 or price <= 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    def objective(sig: float) -> float:\n",
    "        return bs_price(callput, S, K, T, r, borrow_cost, sig) - price\n",
    "\n",
    "    low, high = 1e-4, 3.0\n",
    "    f_low, f_high = objective(low), objective(high)\n",
    "    if f_low * f_high > 0:\n",
    "        return float(\"nan\")\n",
    "    return float(brentq(objective, low, high, xtol=tol, rtol=tol))\n",
    "\n",
    "\n",
    "def default_intensity_fcn(t: float, S: float, b: float, p: float, Sref: float = S0) -> float:\n",
    "    S_safe = max(S, 1e-12)\n",
    "    return 0.075 * (b + (1.0 - b) * (Sref / S_safe) ** p)\n",
    "\n",
    "\n",
    "def hazard_lambda(S: np.ndarray, b: float, p: float, Sref: float = S0) -> np.ndarray:\n",
    "    S_arr = np.asarray(S, dtype=float)\n",
    "    safe = np.maximum(S_arr, 1e-12)\n",
    "    return 0.075 * (b + (1.0 - b) * (Sref / safe) ** p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_27620\\4202758411.py:24: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return float(np.trapz(rates, knots))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cp</th>\n",
       "      <th>K</th>\n",
       "      <th>mid</th>\n",
       "      <th>BS_px (q=0)</th>\n",
       "      <th>JtD_px (q_eff=0.075)</th>\n",
       "      <th>abs_err</th>\n",
       "      <th>rel_err</th>\n",
       "      <th>BS_iv</th>\n",
       "      <th>JtD_iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P230</td>\n",
       "      <td>-1</td>\n",
       "      <td>230.0</td>\n",
       "      <td>52.40</td>\n",
       "      <td>52.775003</td>\n",
       "      <td>63.609902</td>\n",
       "      <td>11.209902</td>\n",
       "      <td>0.213929</td>\n",
       "      <td>0.496753</td>\n",
       "      <td>0.594803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P150</td>\n",
       "      <td>-1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>19.45</td>\n",
       "      <td>15.704044</td>\n",
       "      <td>20.475554</td>\n",
       "      <td>1.025554</td>\n",
       "      <td>0.052728</td>\n",
       "      <td>0.551947</td>\n",
       "      <td>0.565858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C370</td>\n",
       "      <td>1</td>\n",
       "      <td>370.0</td>\n",
       "      <td>13.95</td>\n",
       "      <td>30.609283</td>\n",
       "      <td>20.446129</td>\n",
       "      <td>6.496129</td>\n",
       "      <td>0.465672</td>\n",
       "      <td>0.353005</td>\n",
       "      <td>0.413318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  cp      K    mid  BS_px (q=0)  JtD_px (q_eff=0.075)    abs_err  \\\n",
       "0  P230  -1  230.0  52.40    52.775003             63.609902  11.209902   \n",
       "1  P150  -1  150.0  19.45    15.704044             20.475554   1.025554   \n",
       "2  C370   1  370.0  13.95    30.609283             20.446129   6.496129   \n",
       "\n",
       "    rel_err     BS_iv    JtD_iv  \n",
       "0  0.213929  0.496753  0.594803  \n",
       "1  0.052728  0.551947  0.565858  \n",
       "2  0.465672  0.353005  0.413318  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_sigma = 0.50\n",
    "const_lambda = 0.075\n",
    "q_eff = DIVIDEND_YIELD + const_lambda\n",
    "r_bar_opt = average_rate(T_opt)\n",
    "\n",
    "rows = []\n",
    "for quote in option_quotes.itertuples(index=False):\n",
    "    bs_px = bs_price(quote.callput, S0, quote.K, T_opt, r_bar_opt, BORROW_COST_OPTION, const_sigma)\n",
    "    jtd_px = bs_price(quote.callput, S0, quote.K, T_opt, r_bar_opt, q_eff, const_sigma)\n",
    "    abs_err = jtd_px - quote.mid\n",
    "    rel_err = abs_err / quote.mid if quote.mid else float(\"nan\")\n",
    "    bs_iv = implied_vol_with_ragtop(quote.callput, S0, quote.K, T_opt, r_bar_opt, quote.mid, borrow_cost=BORROW_COST_OPTION)\n",
    "    jtd_iv = implied_vol_with_ragtop(quote.callput, S0, quote.K, T_opt, r_bar_opt, jtd_px, borrow_cost=BORROW_COST_OPTION)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"label\": quote.label,\n",
    "            \"cp\": quote.callput,\n",
    "            \"K\": quote.K,\n",
    "            \"mid\": quote.mid,\n",
    "            \"BS_px (q=0)\": bs_px,\n",
    "            \"JtD_px (q_eff=0.075)\": jtd_px,\n",
    "            \"abs_err\": abs_err,\n",
    "            \"rel_err\": rel_err,\n",
    "            \"BS_iv\": bs_iv,\n",
    "            \"JtD_iv\": jtd_iv,\n",
    "        }\n",
    "    )\n",
    "\n",
    "part1_table = pd.DataFrame(rows)\n",
    "\n",
    "# Validate internal consistency: check a put-call parity on one of the market quotes\n",
    "# Use the 230 put to compute an equivalent call price and verify consistency\n",
    "test_K = 230.0\n",
    "test_T = T_opt\n",
    "test_r = r_bar_opt\n",
    "test_q = q_eff\n",
    "test_sigma = const_sigma\n",
    "\n",
    "# For a put at 230, compute the call that should have the same value via parity\n",
    "call_230 = bs_price(+1, S0, test_K, test_T, test_r, test_q, test_sigma)\n",
    "put_230 = bs_price(-1, S0, test_K, test_T, test_r, test_q, test_sigma)\n",
    "\n",
    "# Put-call parity: C - P = S*exp(-q*T) - K*exp(-r*T)\n",
    "parity_lhs = call_230 - put_230\n",
    "parity_rhs = S0 * math.exp(-test_q * test_T) - test_K * math.exp(-test_r * test_T)\n",
    "parity_error = abs(parity_lhs - parity_rhs)\n",
    "\n",
    "if parity_error > 0.01:\n",
    "    print(f\"⚠ Warning: Put-call parity deviation of {parity_error:.4f} at K={test_K}\")\n",
    "    print(f\"  This may indicate a calibration or pricing issue.\")\n",
    "    print(f\"  LHS (C-P) = {parity_lhs:.6f}, RHS (S·df_q - K·df_r) = {parity_rhs:.6f}\")\n",
    "\n",
    "part1_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561584ed",
   "metadata": {},
   "source": [
    "## 3. Option-market calibration on the assignment grid\n",
    "\n",
    "We follow the specification exactly: volatilities $v \\in \\{0.20, 0.25, \\ldots, 0.90\\}$, hazard-shape exponents $p \\in \\{0, \\ldots, 8\\}$, and baseline weights $b \\in \\{1\\%, \\ldots, 10\\%\\}$. Option prices are generated with the default-free Black–Scholes engine `ragtop.black_scholes`; the hazard enters only through the effective dividend shortcut $q_{\\mathrm{eff}} = q + \\lambda_0$, which preserves put–call parity yet does not solve the full jump-to-default SDE. We use this mapping solely to fit the option quotes on the discrete grid; the resulting $(\\sigma, b, p)$ inputs feed the reduced-form convertible-bond PDE with the $(r+\\lambda)$ kill term, $\\lambda R_b N$ recovery source, and early-conversion obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca336fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_27620\\4202758411.py:24: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return float(np.trapz(rates, knots))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>callput</th>\n",
       "      <th>K</th>\n",
       "      <th>mid</th>\n",
       "      <th>iv_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P230</td>\n",
       "      <td>-1</td>\n",
       "      <td>230.0</td>\n",
       "      <td>52.40</td>\n",
       "      <td>0.496753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P150</td>\n",
       "      <td>-1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0.551947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C370</td>\n",
       "      <td>1</td>\n",
       "      <td>370.0</td>\n",
       "      <td>13.95</td>\n",
       "      <td>0.353005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  callput      K    mid  iv_market\n",
       "0  P230       -1  230.0  52.40   0.496753\n",
       "1  P150       -1  150.0  19.45   0.551947\n",
       "2  C370        1  370.0  13.95   0.353005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_iv_rows = []\n",
    "for quote in option_quotes.itertuples(index=False):\n",
    "    iv_mid = implied_vol_with_ragtop(\n",
    "        quote.callput,\n",
    "        S0,\n",
    "        quote.K,\n",
    "        T_opt,\n",
    "        average_rate(T_opt),\n",
    "        quote.mid,\n",
    "        borrow_cost=BORROW_COST_OPTION,\n",
    "    )\n",
    "    market_iv_rows.append({\"label\": quote.label, \"callput\": quote.callput, \"K\": quote.K, \"mid\": quote.mid, \"iv_market\": iv_mid})\n",
    "\n",
    "market_iv_table = pd.DataFrame(market_iv_rows)\n",
    "market_iv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f2d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration grid sweep is disabled. Set RUN_HEAVY=True to execute the full grid.\n"
     ]
    }
   ],
   "source": [
    "calibration_grid_df = None\n",
    "best_calibration = None\n",
    "best_option_errors = None\n",
    "\n",
    "sigma_grid = np.arange(0.20, 0.901, 0.05)\n",
    "p_grid = np.arange(0, 9, 1)\n",
    "b_grid = np.arange(0.01, 0.101, 0.01)\n",
    "\n",
    "if RUN_HEAVY:\n",
    "    records = []\n",
    "    market_iv_lookup = {row.label: row.iv_market for row in market_iv_table.itertuples(index=False)}\n",
    "    rate_avg = average_rate(T_opt)\n",
    "    for sigma in sigma_grid:\n",
    "        for b in b_grid:\n",
    "            for p in p_grid:\n",
    "                lambda0 = default_intensity_fcn(0.0, S0, b, p)\n",
    "                borrow_eff = DIVIDEND_YIELD + lambda0\n",
    "                price_errors = []\n",
    "                iv_errors = []\n",
    "                for quote in option_quotes.itertuples(index=False):\n",
    "                    model_price = bs_price(quote.callput, S0, quote.K, T_opt, rate_avg, borrow_eff, sigma)\n",
    "                    price_errors.append(model_price - quote.mid)\n",
    "                    model_iv = implied_vol_with_ragtop(\n",
    "                        quote.callput,\n",
    "                        S0,\n",
    "                        quote.K,\n",
    "                        T_opt,\n",
    "                        rate_avg,\n",
    "                        model_price,\n",
    "                        borrow_cost=BORROW_COST_OPTION,\n",
    "                    )\n",
    "                    market_iv = market_iv_lookup[quote.label]\n",
    "                    iv_errors.append(model_iv - market_iv)\n",
    "                rmse_price = float(np.sqrt(np.mean(np.square(price_errors))))\n",
    "                rmse_iv = float(np.sqrt(np.mean(np.square(iv_errors))))\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"sigma\": sigma,\n",
    "                        \"b\": b,\n",
    "                        \"p\": p,\n",
    "                        \"lambda0\": lambda0,\n",
    "                        \"rmse_price\": rmse_price,\n",
    "                        \"rmse_iv\": rmse_iv,\n",
    "                    }\n",
    "                )\n",
    "    calibration_grid_df = pd.DataFrame(records).sort_values(\"rmse_iv\").reset_index(drop=True)\n",
    "    best_calibration = calibration_grid_df.iloc[0].to_dict()\n",
    "\n",
    "    detail_rows = []\n",
    "    best_sigma = best_calibration[\"sigma\"]\n",
    "    best_b = best_calibration[\"b\"]\n",
    "    best_p = best_calibration[\"p\"]\n",
    "    lambda0 = best_calibration[\"lambda0\"]\n",
    "    borrow_eff = DIVIDEND_YIELD + lambda0\n",
    "    rate_avg = average_rate(T_opt)\n",
    "    for quote in option_quotes.itertuples(index=False):\n",
    "        model_price = bs_price(quote.callput, S0, quote.K, T_opt, rate_avg, borrow_eff, best_sigma)\n",
    "        error = model_price - quote.mid\n",
    "        model_iv = implied_vol_with_ragtop(\n",
    "            quote.callput,\n",
    "            S0,\n",
    "            quote.K,\n",
    "            T_opt,\n",
    "            rate_avg,\n",
    "            model_price,\n",
    "            borrow_cost=BORROW_COST_OPTION,\n",
    "        )\n",
    "        detail_rows.append(\n",
    "            {\n",
    "                \"label\": quote.label,\n",
    "                \"model_price\": model_price,\n",
    "                \"mid\": quote.mid,\n",
    "                \"price_error\": error,\n",
    "                \"model_iv\": model_iv,\n",
    "                \"market_iv\": market_iv_lookup[quote.label],\n",
    "            }\n",
    "        )\n",
    "    best_option_errors = pd.DataFrame(detail_rows)\n",
    "\n",
    "    if SAVE_ARTIFACTS:\n",
    "        calibration_grid_df.to_csv(ART_DIR / \"cb_calibration_grid.csv\", index=False)\n",
    "        best_option_errors.to_csv(ART_DIR / \"cb_best_option_errors.csv\", index=False)\n",
    "else:\n",
    "    print(\"Calibration grid sweep is disabled. Set RUN_HEAVY=True to execute the full grid.\")\n",
    "\n",
    "if RUN_HEAVY:\n",
    "    if best_calibration is not None:\n",
    "        display(calibration_grid_df.head())\n",
    "        display(best_option_errors)\n",
    "    else:\n",
    "        print(\"Calibration results unavailable; run the calibration grid first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066d846",
   "metadata": {},
   "source": [
    "*Calibration outputs (shown when `RUN_HEAVY=True`):* `calibration_grid_df.head()` lists the best grid rows sorted by IV RMSE, and `best_option_errors` summarises per-option price and IV errors at that best triple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ae03c",
   "metadata": {},
   "source": [
    "## 4. Convertible bond PDE solver\n",
    "\n",
    "We implement a Crank–Nicolson finite-difference engine with a Rannacher start, state-dependent intensity, and an early-conversion obstacle. The solver supports both PSOR and penalty formulations so we can verify the continuation region is genuine (rather than a numerical artefact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0600510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spot_grid(S_min: float, S_max: float, n_points: int, log_spacing: bool = True) -> np.ndarray:\n",
    "    S_min = max(S_min, 1e-6)\n",
    "    if log_spacing:\n",
    "        return np.exp(np.linspace(np.log(S_min), np.log(S_max), n_points))\n",
    "    return np.linspace(S_min, S_max, n_points)\n",
    "\n",
    "\n",
    "def build_operator(\n",
    "    S_grid: np.ndarray,\n",
    "    sigma: float,\n",
    "    r_val: float,\n",
    "    q_val: float,\n",
    "    hazard: np.ndarray,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    n = len(S_grid)\n",
    "    lower = np.zeros(n)\n",
    "    diag = np.zeros(n)\n",
    "    upper = np.zeros(n)\n",
    "\n",
    "    alpha = 0.5 * sigma ** 2 * S_grid ** 2\n",
    "    beta = (r_val - q_val) * S_grid\n",
    "    gamma = -(r_val + hazard)\n",
    "\n",
    "    for i in range(1, n - 1):\n",
    "        d_down = S_grid[i] - S_grid[i - 1]\n",
    "        d_up = S_grid[i + 1] - S_grid[i]\n",
    "        second_lower = 2.0 / (d_down * (d_down + d_up))\n",
    "        second_upper = 2.0 / (d_up * (d_down + d_up))\n",
    "        second_diag = -second_lower - second_upper\n",
    "\n",
    "        first_lower = -d_up / (d_down * (d_down + d_up))\n",
    "        first_upper = d_down / (d_up * (d_down + d_up))\n",
    "        first_diag = -first_lower - first_upper\n",
    "\n",
    "        lower[i] = alpha[i] * second_lower + beta[i] * first_lower\n",
    "        diag[i] = alpha[i] * second_diag + beta[i] * first_diag + gamma[i]\n",
    "        upper[i] = alpha[i] * second_upper + beta[i] * first_upper\n",
    "\n",
    "    return lower, diag, upper\n",
    "\n",
    "\n",
    "def apply_operator(lower: np.ndarray, diag: np.ndarray, upper: np.ndarray, vec: np.ndarray) -> np.ndarray:\n",
    "    out = np.zeros_like(vec)\n",
    "    out[1:-1] = lower[1:-1] * vec[:-2] + diag[1:-1] * vec[1:-1] + upper[1:-1] * vec[2:]\n",
    "    return out\n",
    "\n",
    "\n",
    "def solve_tridiagonal(lower: np.ndarray, diag: np.ndarray, upper: np.ndarray, rhs: np.ndarray) -> np.ndarray:\n",
    "    n = len(rhs)\n",
    "    a = lower.copy()\n",
    "    b = diag.copy()\n",
    "    c = upper.copy()\n",
    "    d = rhs.copy()\n",
    "\n",
    "    for i in range(1, n):\n",
    "        if abs(b[i - 1]) < 1e-14:\n",
    "            continue\n",
    "        w = a[i] / b[i - 1]\n",
    "        b[i] -= w * c[i - 1]\n",
    "        d[i] -= w * d[i - 1]\n",
    "    x = np.zeros_like(rhs)\n",
    "    x[-1] = d[-1] / b[-1]\n",
    "    for i in range(n - 2, -1, -1):\n",
    "        if abs(b[i]) < 1e-14:\n",
    "            x[i] = x[i + 1]\n",
    "        else:\n",
    "            x[i] = (d[i] - c[i] * x[i + 1]) / b[i]\n",
    "    return x\n",
    "\n",
    "\n",
    "def solve_convertible_cb(\n",
    "    sigma: float,\n",
    "    hazard_profile: Callable[[np.ndarray], np.ndarray],\n",
    "    r_fn: Callable[[float], float],\n",
    "    q_fn: Callable[[float], float],\n",
    "    T: float,\n",
    "    N: float,\n",
    "    CR: float,\n",
    "    R_b: float,\n",
    "    S0_eval: float,\n",
    "    *,\n",
    "    n_space: Optional[int] = None,\n",
    "    n_time: Optional[int] = None,\n",
    "    theta: float = 0.5,\n",
    "    log_spacing: bool = True,\n",
    "    method: str = \"psor\",\n",
    "    psor_omega: float = 1.4,\n",
    "    max_iter: int = 800,\n",
    "    tol: float = 1e-10,\n",
    "    allow_penalty_retry: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    n_space = int(n_space or (600 if RUN_HEAVY else 260))\n",
    "    n_time = int(n_time or (2400 if RUN_HEAVY else 900))\n",
    "\n",
    "    S_min = max(1e-3, S0_eval / 25.0)\n",
    "    S_max = 8.0 * max(S0_eval, 260.0)\n",
    "    S_grid = make_spot_grid(S_min, S_max, n_space, log_spacing=log_spacing)\n",
    "    payoff = np.maximum(N, CR * S_grid)\n",
    "    V = payoff.copy()\n",
    "    obstacle = CR * S_grid\n",
    "\n",
    "    dt = T / n_time\n",
    "    if dt <= 0:\n",
    "        raise ValueError(\"Non-positive timestep\")\n",
    "\n",
    "    steps = []\n",
    "    thetas = []\n",
    "    if theta != 0.5:\n",
    "        raise ValueError(\"theta other than 0.5 not supported in Rannacher schedule\")\n",
    "    steps.extend([dt / 2.0, dt / 2.0])\n",
    "    thetas.extend([1.0, 1.0])\n",
    "    steps.extend([dt] * (n_time - 1))\n",
    "    thetas.extend([theta] * (n_time - 1))\n",
    "\n",
    "    current_time = T\n",
    "    r_prev = r_fn(current_time)\n",
    "    q_prev = q_fn(current_time)\n",
    "    hazard_prev = hazard_profile(S_grid)\n",
    "    lower_prev, diag_prev, upper_prev = build_operator(S_grid, sigma, r_prev, q_prev, hazard_prev)\n",
    "\n",
    "    iter_log = []\n",
    "\n",
    "    for k, (dt_step, theta_step) in enumerate(zip(steps, thetas), start=1):\n",
    "        new_time = max(0.0, current_time - dt_step)\n",
    "        r_new = r_fn(new_time)\n",
    "        q_new = q_fn(new_time)\n",
    "        hazard_new = hazard_profile(S_grid)\n",
    "        lower_new, diag_new, upper_new = build_operator(S_grid, sigma, r_new, q_new, hazard_new)\n",
    "\n",
    "        A_l = -theta_step * dt_step * lower_new\n",
    "        A_d = 1.0 - theta_step * dt_step * diag_new\n",
    "        A_u = -theta_step * dt_step * upper_new\n",
    "\n",
    "        rhs = V.copy()\n",
    "        rhs += dt_step * ((1.0 - theta_step) * apply_operator(lower_prev, diag_prev, upper_prev, V))\n",
    "        source_term = (theta_step * hazard_new + (1.0 - theta_step) * hazard_prev) * R_b * N\n",
    "        rhs += dt_step * source_term\n",
    "\n",
    "        # Left boundary (bond ODE backward Euler)\n",
    "        lam_left = hazard_new[0]\n",
    "        rhs[0] = (V[0] + dt_step * lam_left * R_b * N) / (1.0 + dt_step * (r_new + lam_left))\n",
    "        A_l[0] = 0.0\n",
    "        A_u[0] = 0.0\n",
    "        A_d[0] = 1.0\n",
    "\n",
    "        # Right boundary (Neumann: V_S = CR)\n",
    "        # Enforce an approximate Neumann condition V_S(S_max)=CR so that at large spot levels the surface carries the\n",
    "        # equity-like slope equal to the conversion ratio. This prevents artificial reflection at the far boundary\n",
    "        # and matches the dominance of the conversion value over the bond floor when S is very high.\n",
    "        dS_right = S_grid[-1] - S_grid[-2]\n",
    "        rhs[-1] = CR * dS_right\n",
    "        A_l[-1] = -1.0\n",
    "        A_d[-1] = 1.0\n",
    "        A_u[-1] = 0.0\n",
    "\n",
    "        if method.lower() == \"psor\":\n",
    "            V_new = V.copy()\n",
    "            residual = 1.0\n",
    "            sweep = 0\n",
    "            while sweep < max_iter and residual > tol:\n",
    "                residual = 0.0\n",
    "                for i in range(1, n_space - 1):\n",
    "                    rhs_i = rhs[i] - A_l[i] * V_new[i - 1] - A_u[i] * V_new[i + 1]\n",
    "                    x_i = (1.0 - psor_omega) * V_new[i] + (psor_omega / A_d[i]) * rhs_i\n",
    "                    projected = max(obstacle[i], x_i)\n",
    "                    residual = max(residual, abs(projected - V_new[i]))\n",
    "                    V_new[i] = projected\n",
    "                sweep += 1\n",
    "            if VERBOSE and (k <= 3 or k % 200 == 0):\n",
    "                iter_log.append((k, new_time, sweep, residual))\n",
    "            V = V_new\n",
    "        else:\n",
    "            penalty = 1e6\n",
    "            V_new = V.copy()\n",
    "            for sweep in range(min(6, max_iter)):\n",
    "                diag_mod = A_d.copy()\n",
    "                rhs_mod = rhs.copy()\n",
    "                active = V_new < obstacle\n",
    "                diag_mod[active] += penalty\n",
    "                rhs_mod[active] += penalty * obstacle[active]\n",
    "                V_new = solve_tridiagonal(A_l, diag_mod, A_u, rhs_mod)\n",
    "                V_new = np.maximum(V_new, obstacle)\n",
    "            V = V_new\n",
    "\n",
    "        current_time = new_time\n",
    "        r_prev, q_prev = r_new, q_new\n",
    "        hazard_prev = hazard_new\n",
    "        lower_prev, diag_prev, upper_prev = lower_new, diag_new, upper_new\n",
    "\n",
    "    price = float(np.interp(S0_eval, S_grid, V))\n",
    "    continuation_gap = V - obstacle\n",
    "    max_gap = float(np.max(continuation_gap))\n",
    "\n",
    "    if allow_penalty_retry and method.lower() == \"psor\" and max_gap <= 1e-4:\n",
    "        if VERBOSE:\n",
    "            print(\"PSOR solver produced no clear continuation region; retrying with penalty method.\")\n",
    "        return solve_convertible_cb(\n",
    "            sigma,\n",
    "            hazard_profile,\n",
    "            r_fn,\n",
    "            q_fn,\n",
    "            T,\n",
    "            N,\n",
    "            CR,\n",
    "            R_b,\n",
    "            S0_eval,\n",
    "            n_space=int(n_space * 1.25),\n",
    "            n_time=int(n_time * 1.25),\n",
    "            theta=theta,\n",
    "            log_spacing=log_spacing,\n",
    "            method=\"penalty\",\n",
    "            psor_omega=psor_omega,\n",
    "            max_iter=max_iter,\n",
    "            tol=tol,\n",
    "            allow_penalty_retry=False,\n",
    "        )\n",
    "\n",
    "    positive_indices = np.where(continuation_gap > 1e-4)[0]\n",
    "\n",
    "    return {\n",
    "        \"price\": price,\n",
    "        \"S_grid\": S_grid,\n",
    "        \"values\": V,\n",
    "        \"obstacle\": obstacle,\n",
    "        \"continuation_gap\": continuation_gap,\n",
    "        \"positive_indices\": positive_indices,\n",
    "        \"log\": iter_log,\n",
    "        \"n_space\": n_space,\n",
    "        \"n_time\": n_time,\n",
    "        \"method\": method,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fa7f8",
   "metadata": {},
   "source": [
    "### Constant-parameter CB check (small grid)\n",
    "\n",
    "The following cell mirrors Part 1 by using $\\sigma=50\\%$ and $\\lambda=7.5\\%$ on a tiny grid. The computation is gated and intended to be rerun later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7981958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_HEAVY=False → skipping the constant-parameter CB check (set RUN_HEAVY=True to execute).\n"
     ]
    }
   ],
   "source": [
    "def risky_bond_floor_constant(N: float, r: float, lam: float, T: float, R_b: float) -> float:\n",
    "    if r + lam == 0:\n",
    "        return N\n",
    "    term = math.exp(-(r + lam) * T)\n",
    "    return N * (R_b * lam / (r + lam) * (1.0 - term) + term)\n",
    "\n",
    "\n",
    "if RUN_HEAVY:\n",
    "    const_hazard_fn = lambda S: np.full_like(np.asarray(S, dtype=float), const_lambda)\n",
    "    const_cb = solve_convertible_cb(\n",
    "        sigma=const_sigma,\n",
    "        hazard_profile=const_hazard_fn,\n",
    "        r_fn=r_of,\n",
    "        q_fn=lambda _t: DIVIDEND_YIELD,\n",
    "        T=T_cb,\n",
    "        N=NOTIONAL,\n",
    "        CR=CONVERSION_RATIO,\n",
    "        R_b=RECOVERY_BOND,\n",
    "        S0_eval=S0,\n",
    "        n_space=200,\n",
    "        n_time=600,\n",
    "    )\n",
    "    r_bar_cb = average_rate(T_cb)\n",
    "    floor_val = risky_bond_floor_constant(NOTIONAL, r_bar_cb, const_lambda, T_cb, RECOVERY_BOND)\n",
    "    conversion = CONVERSION_RATIO * S0\n",
    "    assert floor_val <= const_cb[\"price\"] <= conversion + 1e-6\n",
    "    display({\n",
    "        \"CB_price\": const_cb[\"price\"],\n",
    "        \"conversion\": conversion,\n",
    "        \"risky_floor\": floor_val,\n",
    "        \"continuation_gap_max\": float(np.max(const_cb[\"continuation_gap\"])),\n",
    "    })\n",
    "else:\n",
    "    print(\"RUN_HEAVY=False → skipping the constant-parameter CB check (set RUN_HEAVY=True to execute).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00703953",
   "metadata": {},
   "source": [
    "## 5. Part 3 — Convertible pricing under calibrated and nearby parameters\n",
    "\n",
    "Once the option calibration grid is executed we reuse the best $(v,b,p)$ triple together with nearby perturbations to illustrate sensitivity. Each run checks for a non-trivial continuation region and enforces grid robustness when heavy mode is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_HEAVY=False → convertible PDE scenarios are prepared but not executed.\n"
     ]
    }
   ],
   "source": [
    "def approximate_risky_floor(lambda_at_spot: float) -> float:\n",
    "    r_bar_cb = average_rate(T_cb)\n",
    "    lam = float(lambda_at_spot)\n",
    "    return risky_bond_floor_constant(NOTIONAL, r_bar_cb, lam, T_cb, RECOVERY_BOND)\n",
    "\n",
    "\n",
    "def cb_price_from_params(sigma: float, b: float, p: float, *, n_space: Optional[int] = None, n_time: Optional[int] = None) -> Dict[str, object]:\n",
    "    hazard_fn = lambda S: hazard_lambda(S, b, p)\n",
    "    result = solve_convertible_cb(\n",
    "        sigma=sigma,\n",
    "        hazard_profile=hazard_fn,\n",
    "        r_fn=r_of,\n",
    "        q_fn=lambda _t: DIVIDEND_YIELD,\n",
    "        T=T_cb,\n",
    "        N=NOTIONAL,\n",
    "        CR=CONVERSION_RATIO,\n",
    "        R_b=RECOVERY_BOND,\n",
    "        S0_eval=S0,\n",
    "        n_space=n_space,\n",
    "        n_time=n_time,\n",
    "        method=\"psor\",\n",
    "    )\n",
    "    if result[\"positive_indices\"].size == 0 and RUN_HEAVY:\n",
    "        if VERBOSE:\n",
    "            print(\"Upscaling grid because no continuation region was detected.\")\n",
    "        result = solve_convertible_cb(\n",
    "            sigma=sigma,\n",
    "            hazard_profile=hazard_fn,\n",
    "            r_fn=r_of,\n",
    "            q_fn=lambda _t: DIVIDEND_YIELD,\n",
    "            T=T_cb,\n",
    "            N=NOTIONAL,\n",
    "            CR=CONVERSION_RATIO,\n",
    "            R_b=RECOVERY_BOND,\n",
    "            S0_eval=S0,\n",
    "            n_space=int((n_space or (600 if RUN_HEAVY else 260)) * 1.4),\n",
    "            n_time=int((n_time or (2400 if RUN_HEAVY else 900)) * 1.4),\n",
    "            method=\"penalty\",\n",
    "        )\n",
    "    return result\n",
    "\n",
    "\n",
    "if RUN_HEAVY and best_calibration is not None:\n",
    "    base_sigma = best_calibration[\"sigma\"]\n",
    "    base_b = best_calibration[\"b\"]\n",
    "    base_p = best_calibration[\"p\"]\n",
    "    base_lambda = default_intensity_fcn(0.0, S0, base_b, base_p)\n",
    "    print(f\"Best (sigma, b, p) = ({base_sigma:.2%}, {base_b:.2%}, {base_p:.0f}); lambda(S0) = {base_lambda:.4%}\")\n",
    "\n",
    "    scenarios = [\n",
    "        (\"calibrated\", base_sigma, base_b, base_p),\n",
    "        (\"low_sigma\", max(0.20, base_sigma - 0.05), base_b, max(0, base_p - 1)),\n",
    "        (\"high_sigma\", min(0.90, base_sigma + 0.05), min(0.10, base_b + 0.02), min(8, base_p + 1)),\n",
    "        (\"higher_b\", base_sigma, min(0.10, base_b + 0.02), base_p),\n",
    "    ]\n",
    "\n",
    "    cb_rows = []\n",
    "    for tag, sigma, b, p in scenarios:\n",
    "        result = cb_price_from_params(sigma, b, p)\n",
    "        lambda_spot = default_intensity_fcn(0.0, S0, b, p)\n",
    "        floor_val = approximate_risky_floor(lambda_spot)\n",
    "        conversion_val = CONVERSION_RATIO * S0\n",
    "        gap_max = float(np.max(result[\"continuation_gap\"]))\n",
    "        assert gap_max > 1e-4 or abs(result[\"price\"] - conversion_val) < 1e-3\n",
    "        cb_rows.append(\n",
    "            {\n",
    "                \"tag\": tag,\n",
    "                \"sigma\": sigma,\n",
    "                \"b\": b,\n",
    "                \"p\": p,\n",
    "                \"lambda(S0)\": lambda_spot,\n",
    "                \"CB_PV\": result[\"price\"],\n",
    "                \"Conv (CR*S0)\": conversion_val,\n",
    "                \"Floor (approx)\": floor_val,\n",
    "                \"max_gap\": gap_max,\n",
    "                \"grid\": (result[\"n_space\"], result[\"n_time\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if RUN_HEAVY:\n",
    "            refined = cb_price_from_params(sigma, b, p, n_space=int(result[\"n_space\"] * 1.1), n_time=int(result[\"n_time\"] * 1.1))\n",
    "            diff = abs(refined[\"price\"] - result[\"price\"])\n",
    "            reference = max(1.0, refined[\"price\"])\n",
    "            assert diff / reference < 5e-4, \"Grid robustness check failed (>5 bps).\"\n",
    "\n",
    "        positive_nodes = result[\"positive_indices\"]\n",
    "        if VERBOSE:\n",
    "            if positive_nodes.size:\n",
    "                idx_sample = positive_nodes[:5]\n",
    "                s_vals = result[\"S_grid\"][idx_sample]\n",
    "                gaps = result[\"continuation_gap\"][idx_sample]\n",
    "                print(f\"{tag}: continuation nodes (sample) -> {list(zip(np.round(s_vals,2), np.round(gaps,4)))}\")\n",
    "            else:\n",
    "                print(f\"{tag}: continuation region touches conversion boundary (gap max={gap_max:.2e}).\")\n",
    "\n",
    "    cb_results_df = pd.DataFrame(cb_rows)\n",
    "    if SAVE_ARTIFACTS:\n",
    "        cb_results_df.to_csv(ART_DIR / \"cb_pricing_scenarios.csv\", index=False)\n",
    "    cb_results_df\n",
    "elif RUN_HEAVY:\n",
    "    print(\"Calibration results unavailable; run the calibration grid first.\")\n",
    "else:\n",
    "    print(\"RUN_HEAVY=False → convertible PDE scenarios are prepared but not executed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13a41a",
   "metadata": {},
   "source": [
    "## 6. Part 4 — Convertible value versus spot (preview loop)\n",
    "\n",
    "A spot sweep illustrates the floor, continuation, and early-conversion regimes. The code is provided but left unexecuted by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_HEAVY=False → spot sweep is disabled. Enable heavy mode for the full plot.\n"
     ]
    }
   ],
   "source": [
    "if RUN_HEAVY and best_calibration is not None:\n",
    "    spots = np.linspace(20.0, 500.0, 25)\n",
    "    values = []\n",
    "    for s in spots:\n",
    "        hazard_fn = lambda S: hazard_lambda(S, best_calibration[\"b\"], best_calibration[\"p\"])\n",
    "        result = solve_convertible_cb(\n",
    "            sigma=best_calibration[\"sigma\"],\n",
    "            hazard_profile=hazard_fn,\n",
    "            r_fn=r_of,\n",
    "            q_fn=lambda _t: DIVIDEND_YIELD,\n",
    "            T=T_cb,\n",
    "            N=NOTIONAL,\n",
    "            CR=CONVERSION_RATIO,\n",
    "            R_b=RECOVERY_BOND,\n",
    "            S0_eval=s,\n",
    "            n_space=320,\n",
    "            n_time=900,\n",
    "        )\n",
    "        lam_spot = default_intensity_fcn(0.0, s, best_calibration[\"b\"], best_calibration[\"p\"])\n",
    "        floor_val = approximate_risky_floor(lam_spot)\n",
    "        values.append(\n",
    "            {\n",
    "                \"S\": s,\n",
    "                \"CB\": result[\"price\"],\n",
    "                \"Conversion\": CONVERSION_RATIO * s,\n",
    "                \"Floor\": floor_val,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    sweep_df = pd.DataFrame(values)\n",
    "    if SAVE_ARTIFACTS:\n",
    "        sweep_df.to_csv(ART_DIR / \"cb_spot_sweep.csv\", index=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "    ax.plot(sweep_df[\"S\"], sweep_df[\"CB\"], label=\"Convertible\")\n",
    "    ax.plot(sweep_df[\"S\"], sweep_df[\"Conversion\"], label=\"Conversion value\", linestyle=\"--\")\n",
    "    ax.plot(sweep_df[\"S\"], sweep_df[\"Floor\"], label=\"Risky floor\", linestyle=\":\")\n",
    "    ax.set_xlabel(\"Spot level\")\n",
    "    ax.set_ylabel(\"Present value\")\n",
    "    ax.set_title(\"Convertible value vs spot (preview grid)\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "else:\n",
    "    print(\"RUN_HEAVY=False → spot sweep is disabled. Enable heavy mode for the full plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02812dcc",
   "metadata": {},
   "source": [
    "## 7. Appendix — Controls & reproducibility\n",
    "\n",
    "* Toggle `RUN_HEAVY` to `True` before executing the calibration grid or the PDE sweeps.\n",
    "* The FD solver defaults to log-spaced spot grids, Rannacher start, PSOR enforcement, and automatically retries with the penalty formulation if no continuation region appears.\n",
    "* All optional CSV exports land in `../artifacts/` when `SAVE_ARTIFACTS` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b6ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heavy runs are disabled. Set RUN_HEAVY=True to execute calibration grids and PDE sweeps.\n"
     ]
    }
   ],
   "source": [
    "if RUN_HEAVY:\n",
    "    print(\"Heavy runs are enabled — expect longer runtimes for calibration and FD pricing.\")\n",
    "else:\n",
    "    print(\"Heavy runs are disabled. Set RUN_HEAVY=True to execute calibration grids and PDE sweeps.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

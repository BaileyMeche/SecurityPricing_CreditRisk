{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be72118",
   "metadata": {},
   "source": [
    "# Binomial Tree\n",
    "## Instructions\n",
    "\n",
    "Enhance your binomial tree pricer, or write a new one, with the following features:\n",
    "\n",
    "Start on 3 nodes instead of 1\n",
    "* Simultaneously price both a European and an American exercise version of the call or put\n",
    "* Use finite differences on the initial 3 nodes to obtain tree-derived delta and gamma\n",
    "* Use the Black-Scholes formulas to get an \"exact\" European option value and delta and gamma\n",
    "* Compute the control-variate-corrected American option price\n",
    "* Compute the control-variate-corrected American option delta and gamma\n",
    "\n",
    "Have your tree function return the following 12 values:\n",
    "* European option value, delta and gamma from Black Scholes Formulas\n",
    "* European option value, delta and gamma from the tree\n",
    "* Uncorrected American option value, delta and gamma from the tree\n",
    "* Control-variate-corrected American option value $V_{CV}$, delta and gamma\n",
    "* Study the case with $S_0=50, T=0.1, r = 0.1, q=0.02, \\sigma=0.3$\n",
    "\n",
    "Use your tree on two put options: strike 46 and strike 53.\n",
    "\n",
    "Run your tree with 1,000 steps to find a proxy $X_V, X_\\Delta, X_\\Gamma$ for the \"exact\" value, delta and gamma of the American option (use the CV-corrected outputs).  You can use $X_V, X_\\Delta, X_\\Gamma$ to form error estimates for numbers coming from smaller trees. Now run \"big trees\" with 100, 105, 110 and 120 steps, and take the average error from the uncorrected values, then the uncorrected deltas and the uncorrected gammas, $E_V^H, E_\\Delta^H, E_\\Gamma^H$.\n",
    "Now, find the (smaller) number of steps your tree can use where it achieves roughly the same error size from its CV-corrected computations as the $E^H$  above.  Estimate the associated savings in computational complexity, as a multiplicative factor (i.e. if the CV tree needs only 33 steps that is roughly a 3x improvement).\n",
    "\n",
    "Do it separately for value, delta and put strike (so, ultimately, you have to do this four times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6050d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:43.807309Z",
     "iopub.status.busy": "2025-11-10T22:01:43.806997Z",
     "iopub.status.idle": "2025-11-10T22:01:45.373181Z",
     "shell.execute_reply": "2025-11-10T22:01:45.372403Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass, field, replace\n",
    "from functools import lru_cache\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style='whitegrid')\n",
    "pd.options.display.float_format = '{:.6f}'.format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c33c2",
   "metadata": {},
   "source": [
    "## Black–Scholes (European) value, $\\Delta, \\Gamma, \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce2051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:45.379502Z",
     "iopub.status.busy": "2025-11-10T22:01:45.378742Z",
     "iopub.status.idle": "2025-11-10T22:01:45.387865Z",
     "shell.execute_reply": "2025-11-10T22:01:45.386961Z"
    }
   },
   "outputs": [],
   "source": [
    "OptionType = Literal['call', 'put']\n",
    "\n",
    "def _bs_d1_d2(S, K, r, q, sigma, T):\n",
    "    if T <= 0:\n",
    "        raise ValueError('T must be positive for BS Greeks.')\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r - q + 0.5 * sigma * sigma) * T) / (sigma * sqrtT)\n",
    "    d2 = d1 - sigma * sqrtT\n",
    "    return d1, d2\n",
    "\n",
    "def bs_value_delta_gamma_theta(option: OptionType, S, K, r, q, sigma, T):\n",
    "    if T <= 0:\n",
    "        payoff = max(S - K, 0.0) if option == 'call' else max(K - S, 0.0)\n",
    "        if option == 'call':\n",
    "            delta = 1.0 if S > K else 0.0\n",
    "        else:\n",
    "            delta = -1.0 if K > S else 0.0\n",
    "        gamma = 0.0\n",
    "        theta = 0.0\n",
    "        return payoff, delta, gamma, theta\n",
    "    d1, d2 = _bs_d1_d2(S, K, r, q, sigma, T)\n",
    "    disc_q = math.exp(-q * T)\n",
    "    disc_r = math.exp(-r * T)\n",
    "    sqrtT = math.sqrt(T)\n",
    "    pdf_d1 = norm.pdf(d1)\n",
    "    if option == 'call':\n",
    "        value = disc_q * S * norm.cdf(d1) - disc_r * K * norm.cdf(d2)\n",
    "        delta = disc_q * norm.cdf(d1)\n",
    "        theta = (-disc_q * S * pdf_d1 * sigma / (2 * sqrtT)\n",
    "                 - r * K * disc_r * norm.cdf(d2)\n",
    "                 + q * S * disc_q * norm.cdf(d1))\n",
    "    else:\n",
    "        value = disc_r * K * norm.cdf(-d2) - disc_q * S * norm.cdf(-d1)\n",
    "        delta = disc_q * (norm.cdf(d1) - 1.0)\n",
    "        theta = (-disc_q * S * pdf_d1 * sigma / (2 * sqrtT)\n",
    "                 + r * K * disc_r * norm.cdf(-d2)\n",
    "                 - q * S * disc_q * norm.cdf(-d1))\n",
    "    gamma = disc_q * pdf_d1 / (S * sigma * sqrtT)\n",
    "    return value, delta, gamma, theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb7cb7",
   "metadata": {},
   "source": [
    "## Binomial trees with CV Americans, $\\Gamma$ smoothing, and alternate parametrisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c4826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:45.390745Z",
     "iopub.status.busy": "2025-11-10T22:01:45.390553Z",
     "iopub.status.idle": "2025-11-10T22:01:45.441707Z",
     "shell.execute_reply": "2025-11-10T22:01:45.440119Z"
    }
   },
   "outputs": [],
   "source": [
    "def peizer_pratt_method2_inversion(z: float, n: int) -> float:\n",
    "    if n % 2 == 0:\n",
    "        raise ValueError('n must be odd for Peizer–Pratt inversion.')\n",
    "    denom = n + 1.0 / 3.0 + 0.1 / (n + 1.0)\n",
    "    scaled = z / denom\n",
    "    scaled *= scaled\n",
    "    expo = math.exp(-scaled * (n + 1.0 / 6.0))\n",
    "    sign = 1.0 if z > 0 else -1.0\n",
    "    return 0.5 + sign * math.sqrt(0.25 * (1.0 - expo))\n",
    "\n",
    "def central_gamma_nonuniform(values: Tuple[float, float, float], spots: Tuple[float, float, float]) -> float:\n",
    "    dn, mid, up = values\n",
    "    Sd, Sm, Su = spots\n",
    "    h1 = Sm - Sd\n",
    "    h2 = Su - Sm\n",
    "    denom = h1 * h2 * (h1 + h2)\n",
    "    if denom == 0.0:\n",
    "        return 0.0\n",
    "    return 2.0 * (dn / (h1 * (h1 + h2)) - mid / (h1 * h2) + up / (h2 * (h1 + h2)))\n",
    "\n",
    "def payoff(option: OptionType, S: np.ndarray, K: float) -> np.ndarray:\n",
    "    return np.maximum(S - K, 0.0) if option == 'call' else np.maximum(K - S, 0.0)\n",
    "\n",
    "def theta_from_pde(V0: float, delta0: float, gamma0: float, S0: float, r: float, q: float, sigma: float) -> float:\n",
    "    return r * V0 - (r - q) * S0 * delta0 - 0.5 * sigma * sigma * S0 * S0 * gamma0\n",
    "\n",
    "def delta_from_three(values: Tuple[float, float, float], spots: Tuple[float, float, float]) -> float:\n",
    "    v_minus, v0, v_plus = values\n",
    "    s_minus, s0, s_plus = spots\n",
    "    h1 = s0 - s_minus\n",
    "    h2 = s_plus - s0\n",
    "    denom = h1 * h2 * (h1 + h2)\n",
    "    if denom == 0.0:\n",
    "        width = s_plus - s_minus\n",
    "        return 0.0 if width == 0.0 else (v_plus - v_minus) / width\n",
    "    return (h2 * h2 * (v0 - v_minus) + h1 * h1 * (v_plus - v0)) / denom\n",
    "\n",
    "def gamma_from_three(values: Tuple[float, float, float], spots: Tuple[float, float, float]) -> float:\n",
    "    return central_gamma_nonuniform(values, spots)\n",
    "\n",
    "@dataclass\n",
    "class Outputs:\n",
    "    bs_euro_value: float\n",
    "    bs_euro_delta: float\n",
    "    bs_euro_gamma: float\n",
    "    bs_euro_theta: float\n",
    "    euro_value: float\n",
    "    euro_delta: float\n",
    "    euro_gamma: float\n",
    "    euro_theta: float\n",
    "    american_value: float\n",
    "    american_delta: float\n",
    "    american_gamma: float\n",
    "    american_theta: float\n",
    "    cv_value: float\n",
    "    cv_delta: float\n",
    "    cv_gamma: float\n",
    "    cv_theta: float\n",
    "    method: str\n",
    "    gamma_scheme: str\n",
    "    steps_requested: int\n",
    "    steps_used: int\n",
    "    dt: float\n",
    "    u: float\n",
    "    d: float\n",
    "    p: float\n",
    "    extras: Dict[str, Any] = field(default_factory=dict)\n",
    "    stock_levels: Optional[List[np.ndarray]] = None\n",
    "    euro_layers: Optional[List[np.ndarray]] = None\n",
    "    american_layers: Optional[List[np.ndarray]] = None\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TreeParams:\n",
    "    steps_requested: int\n",
    "    steps_used: int\n",
    "    dt: float\n",
    "    u: float\n",
    "    d: float\n",
    "    p: float\n",
    "    disc: float\n",
    "    growth: float\n",
    "\n",
    "    def cache_key(self) -> Tuple[int, int, float, float, float, float, float, float]:\n",
    "        return (\n",
    "            self.steps_requested,\n",
    "            self.steps_used,\n",
    "            self.dt,\n",
    "            self.u,\n",
    "            self.d,\n",
    "            self.p,\n",
    "            self.disc,\n",
    "            self.growth,\n",
    "        )\n",
    "\n",
    "def _compute_tree_params(S0: float, K: float, r: float, q: float, sigma: float, T: float, *, steps: int, method: str) -> TreeParams:\n",
    "    if steps < 2:\n",
    "        raise ValueError('Need at least 2 steps to compute grid-based Greeks.')\n",
    "    method = method.lower()\n",
    "    steps_requested = steps\n",
    "    steps_used = steps\n",
    "    if method == 'lr' and steps_used % 2 == 0:\n",
    "        steps_used += 1\n",
    "    dt = T / steps_used if steps_used > 0 else 0.0\n",
    "    disc = math.exp(-r * dt) if dt > 0 else 1.0\n",
    "    growth = math.exp((r - q) * dt) if dt > 0 else 1.0\n",
    "    if method == 'crr':\n",
    "        u = math.exp(sigma * math.sqrt(dt)) if dt > 0 else 1.0\n",
    "        d = 1.0 / u if u != 0 else 1.0\n",
    "        p = (growth - d) / (u - d) if u != d else 0.5\n",
    "    elif method == 'tian':\n",
    "        qvar = math.exp(sigma * sigma * dt) if dt > 0 else 1.0\n",
    "        rbar = growth * math.sqrt(qvar)\n",
    "        sqrt_term = math.sqrt(max(qvar * qvar + 2.0 * qvar - 3.0, 0.0))\n",
    "        u = 0.5 * rbar * qvar * (qvar + 1.0 + sqrt_term)\n",
    "        d = 0.5 * rbar * qvar * (qvar + 1.0 - sqrt_term)\n",
    "        p = (rbar - d) / (u - d)\n",
    "    elif method == 'lr':\n",
    "        if steps_used % 2 == 0:\n",
    "            raise ValueError('Leisen–Reimer needs an odd number of steps.')\n",
    "        variance = sigma * sigma * T\n",
    "        sqrt_var = math.sqrt(variance)\n",
    "        if sqrt_var == 0.0:\n",
    "            pu = 0.5\n",
    "            pdash = 0.5\n",
    "        else:\n",
    "            d2 = (math.log(S0 / K) + (r - q - 0.5 * sigma * sigma) * T) / sqrt_var\n",
    "            pu = peizer_pratt_method2_inversion(d2, steps_used)\n",
    "            pdash = peizer_pratt_method2_inversion(d2 + sqrt_var, steps_used)\n",
    "        pu = min(max(pu, 1e-12), 1.0 - 1e-12)\n",
    "        u = growth * pdash / pu if pu > 0 else growth\n",
    "        d = (growth - pu * u) / (1.0 - pu) if pu < 1.0 else growth\n",
    "        p = pu\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: {method}')\n",
    "    if not (0.0 <= p <= 1.0):\n",
    "        raise ValueError('Risk-neutral probability out of bounds; adjust inputs.')\n",
    "    return TreeParams(\n",
    "        steps_requested=steps_requested,\n",
    "        steps_used=steps_used,\n",
    "        dt=dt,\n",
    "        u=u,\n",
    "        d=d,\n",
    "        p=p,\n",
    "        disc=disc,\n",
    "        growth=growth,\n",
    "    )\n",
    "\n",
    "def _binomial_tree_single_start(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    method: str = 'crr',\n",
    "    params: Optional[TreeParams] = None,\n",
    "    store_layers: bool = True,\n",
    ") -> Outputs:\n",
    "    method = method.lower()\n",
    "    if params is None:\n",
    "        params = _compute_tree_params(S0, K, r, q, sigma, T, steps=steps, method=method)\n",
    "    steps_used = params.steps_used\n",
    "    dt = params.dt\n",
    "    u = params.u\n",
    "    d = params.d\n",
    "    p = params.p\n",
    "    disc = params.disc\n",
    "    stock_levels: List[np.ndarray] = [np.array([S0], dtype=float)]\n",
    "    for n in range(1, steps_used + 1):\n",
    "        prev = stock_levels[-1]\n",
    "        cur = np.empty(n + 1)\n",
    "        cur[0] = prev[0] * d\n",
    "        cur[1:] = prev * u\n",
    "        stock_levels.append(cur)\n",
    "    euro_vals = payoff(option, stock_levels[-1], K)\n",
    "    amer_vals = euro_vals.copy()\n",
    "    euro_layers: List[Optional[np.ndarray]] = [None] * (steps_used + 1)\n",
    "    amer_layers: List[Optional[np.ndarray]] = [None] * (steps_used + 1)\n",
    "    euro_layers[-1] = euro_vals.copy()\n",
    "    amer_layers[-1] = amer_vals.copy()\n",
    "    for n in range(steps_used - 1, -1, -1):\n",
    "        euro_vals = disc * (p * euro_vals[1:] + (1 - p) * euro_vals[:-1])\n",
    "        amer_vals = disc * (p * amer_vals[1:] + (1 - p) * amer_vals[:-1])\n",
    "        amer_vals = np.maximum(amer_vals, payoff(option, stock_levels[n], K))\n",
    "        euro_layers[n] = euro_vals.copy()\n",
    "        amer_layers[n] = amer_vals.copy()\n",
    "    spots_lvl1 = stock_levels[1]\n",
    "    delta_denom = spots_lvl1[1] - spots_lvl1[0]\n",
    "    euro_delta = (euro_layers[1][1] - euro_layers[1][0]) / delta_denom\n",
    "    american_delta = (amer_layers[1][1] - amer_layers[1][0]) / delta_denom\n",
    "    spots_lvl2 = stock_levels[2]\n",
    "    euro_gamma_central = central_gamma_nonuniform(\n",
    "        (euro_layers[2][0], euro_layers[2][1], euro_layers[2][2]),\n",
    "        (spots_lvl2[0], spots_lvl2[1], spots_lvl2[2]),\n",
    "    )\n",
    "    american_gamma_central = central_gamma_nonuniform(\n",
    "        (amer_layers[2][0], amer_layers[2][1], amer_layers[2][2]),\n",
    "        (spots_lvl2[0], spots_lvl2[1], spots_lvl2[2]),\n",
    "    )\n",
    "    if steps_used >= 3:\n",
    "        spots_lvl3 = stock_levels[3]\n",
    "        euro_gamma_level3 = central_gamma_nonuniform(\n",
    "            (euro_layers[3][1], euro_layers[2][1], euro_layers[3][2]),\n",
    "            (spots_lvl3[1], spots_lvl2[1], spots_lvl3[2]),\n",
    "        )\n",
    "        american_gamma_level3 = central_gamma_nonuniform(\n",
    "            (amer_layers[3][1], amer_layers[2][1], amer_layers[3][2]),\n",
    "            (spots_lvl3[1], spots_lvl2[1], spots_lvl3[2]),\n",
    "        )\n",
    "    else:\n",
    "        euro_gamma_level3 = euro_gamma_central\n",
    "        american_gamma_level3 = american_gamma_central\n",
    "    euro_value = float(euro_layers[0][0])\n",
    "    american_value = float(amer_layers[0][0])\n",
    "    bs_val, bs_delta, bs_gamma, bs_theta = bs_value_delta_gamma_theta(option, S0, K, r, q, sigma, T)\n",
    "    euro_theta = theta_from_pde(euro_value, euro_delta, euro_gamma_central, S0, r, q, sigma)\n",
    "    american_theta = theta_from_pde(american_value, american_delta, american_gamma_central, S0, r, q, sigma)\n",
    "    cv_value = american_value + (bs_val - euro_value)\n",
    "    cv_delta = american_delta + (bs_delta - euro_delta)\n",
    "    cv_gamma = american_gamma_central + (bs_gamma - euro_gamma_central)\n",
    "    cv_theta = american_theta + (bs_theta - euro_theta)\n",
    "    extras = {\n",
    "        'euro_gamma_central': euro_gamma_central,\n",
    "        'american_gamma_central': american_gamma_central,\n",
    "        'euro_gamma_level3': euro_gamma_level3,\n",
    "        'american_gamma_level3': american_gamma_level3,\n",
    "    }\n",
    "    stock_levels_out = stock_levels if store_layers else None\n",
    "    euro_layers_out = euro_layers if store_layers else None\n",
    "    amer_layers_out = amer_layers if store_layers else None\n",
    "\n",
    "    return Outputs(\n",
    "        bs_val,\n",
    "        bs_delta,\n",
    "        bs_gamma,\n",
    "        bs_theta,\n",
    "        euro_value,\n",
    "        euro_delta,\n",
    "        euro_gamma_central,\n",
    "        euro_theta,\n",
    "        american_value,\n",
    "        american_delta,\n",
    "        american_gamma_central,\n",
    "        american_theta,\n",
    "        cv_value,\n",
    "        cv_delta,\n",
    "        cv_gamma,\n",
    "        cv_theta,\n",
    "        method,\n",
    "        'central',\n",
    "        params.steps_requested,\n",
    "        params.steps_used,\n",
    "        params.dt,\n",
    "        params.u,\n",
    "        params.d,\n",
    "        params.p,\n",
    "        extras,\n",
    "        stock_levels_out,\n",
    "        euro_layers_out,\n",
    "        amer_layers_out,\n",
    "    )\n",
    "\n",
    "def _params_from_key(key: Tuple[int, int, float, float, float, float, float, float]) -> TreeParams:\n",
    "    return TreeParams(\n",
    "        steps_requested=key[0],\n",
    "        steps_used=key[1],\n",
    "        dt=key[2],\n",
    "        u=key[3],\n",
    "        d=key[4],\n",
    "        p=key[5],\n",
    "        disc=key[6],\n",
    "        growth=key[7],\n",
    "    )\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def _cached_single_start(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    method: str,\n",
    "    params_key: Tuple[int, int, float, float, float, float, float, float],\n",
    "    store_layers: bool,\n",
    ") -> Outputs:\n",
    "    params = _params_from_key(params_key)\n",
    "    return _binomial_tree_single_start(\n",
    "        option,\n",
    "        S0,\n",
    "        K,\n",
    "        r,\n",
    "        q,\n",
    "        sigma,\n",
    "        T,\n",
    "        steps=params.steps_requested,\n",
    "        method=method,\n",
    "        params=params,\n",
    "        store_layers=store_layers,\n",
    "    )\n",
    "\n",
    "def _three_start_summary(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    method: str,\n",
    "    store_layers_central: bool = True,\n",
    "):\n",
    "    params = _compute_tree_params(S0, K, r, q, sigma, T, steps=steps, method=method)\n",
    "    params_key = params.cache_key()\n",
    "    S_minus = S0 * params.d\n",
    "    S_plus = S0 * params.u\n",
    "    minus = _cached_single_start(option, S_minus, K, r, q, sigma, T, method, params_key, store_layers=False)\n",
    "    central = _cached_single_start(option, S0, K, r, q, sigma, T, method, params_key, store_layers=store_layers_central)\n",
    "    plus = _cached_single_start(option, S_plus, K, r, q, sigma, T, method, params_key, store_layers=False)\n",
    "    spots = (S_minus, S0, S_plus)\n",
    "    euro_values = (minus.euro_value, central.euro_value, plus.euro_value)\n",
    "    american_values = (minus.american_value, central.american_value, plus.american_value)\n",
    "    cv_values = (minus.cv_value, central.cv_value, plus.cv_value)\n",
    "    summary = {\n",
    "        'params': params,\n",
    "        'central': central,\n",
    "        'minus': minus,\n",
    "        'plus': plus,\n",
    "        'spots': spots,\n",
    "        'euro_values': euro_values,\n",
    "        'american_values': american_values,\n",
    "        'cv_values': cv_values,\n",
    "        'euro_delta': delta_from_three(euro_values, spots),\n",
    "        'american_delta': delta_from_three(american_values, spots),\n",
    "        'cv_delta': delta_from_three(cv_values, spots),\n",
    "        'euro_gamma': gamma_from_three(euro_values, spots),\n",
    "        'american_gamma': gamma_from_three(american_values, spots),\n",
    "        'cv_gamma': gamma_from_three(cv_values, spots),\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "def binomial_tree_greeks_on_grids(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    method: str = 'crr',\n",
    "    gamma_scheme: str = 'central',\n",
    ") -> Outputs:\n",
    "    method = method.lower()\n",
    "    summary = _three_start_summary(option, S0, K, r, q, sigma, T, steps=steps, method=method)\n",
    "    params = summary['params']\n",
    "    central = summary['central']\n",
    "    euro_delta = summary['euro_delta']\n",
    "    american_delta = summary['american_delta']\n",
    "    cv_delta = summary['cv_delta']\n",
    "    euro_gamma = summary['euro_gamma']\n",
    "    american_gamma = summary['american_gamma']\n",
    "    cv_gamma = summary['cv_gamma']\n",
    "    extras = dict(central.extras)\n",
    "    extras.update({\n",
    "        'euro_gamma_three_start': euro_gamma,\n",
    "        'american_gamma_three_start': american_gamma,\n",
    "        'cv_gamma_three_start': cv_gamma,\n",
    "        'three_start_spots': summary['spots'],\n",
    "        'three_start_euro_values': summary['euro_values'],\n",
    "        'three_start_american_values': summary['american_values'],\n",
    "        'three_start_cv_values': summary['cv_values'],\n",
    "    })\n",
    "    if gamma_scheme == 'multi-layer':\n",
    "        summary_adj = _three_start_summary(option, S0, K, r, q, sigma, T, steps=steps + 1, method=method, store_layers_central=False)\n",
    "        euro_gamma_adj = summary_adj['euro_gamma']\n",
    "        american_gamma_adj = summary_adj['american_gamma']\n",
    "        cv_gamma_adj = summary_adj['cv_gamma']\n",
    "        euro_gamma_smoothed = 0.5 * (euro_gamma + euro_gamma_adj)\n",
    "        american_gamma_smoothed = 0.5 * (american_gamma + american_gamma_adj)\n",
    "        cv_gamma_smoothed = 0.5 * (cv_gamma + cv_gamma_adj)\n",
    "        extras.update({\n",
    "            'adjacent_steps_used': summary_adj['params'].steps_used,\n",
    "            'euro_gamma_three_start_adjacent': euro_gamma_adj,\n",
    "            'american_gamma_three_start_adjacent': american_gamma_adj,\n",
    "            'cv_gamma_three_start_adjacent': cv_gamma_adj,\n",
    "            'euro_gamma_multi': euro_gamma_smoothed,\n",
    "            'american_gamma_multi': american_gamma_smoothed,\n",
    "            'cv_gamma_multi': cv_gamma_smoothed,\n",
    "        })\n",
    "        euro_gamma_final = euro_gamma_smoothed\n",
    "        american_gamma_final = american_gamma_smoothed\n",
    "        cv_gamma_final = cv_gamma_smoothed\n",
    "    else:\n",
    "        extras.update({\n",
    "            'euro_gamma_multi': euro_gamma,\n",
    "            'american_gamma_multi': american_gamma,\n",
    "            'cv_gamma_multi': cv_gamma,\n",
    "        })\n",
    "        euro_gamma_final = euro_gamma\n",
    "        american_gamma_final = american_gamma\n",
    "        cv_gamma_final = cv_gamma\n",
    "    euro_theta = theta_from_pde(central.euro_value, euro_delta, euro_gamma_final, S0, r, q, sigma)\n",
    "    american_theta = theta_from_pde(central.american_value, american_delta, american_gamma_final, S0, r, q, sigma)\n",
    "    cv_theta = american_theta + (central.bs_euro_theta - euro_theta)\n",
    "    result = replace(\n",
    "        central,\n",
    "        euro_delta=euro_delta,\n",
    "        euro_gamma=euro_gamma_final,\n",
    "        euro_theta=euro_theta,\n",
    "        american_delta=american_delta,\n",
    "        american_gamma=american_gamma_final,\n",
    "        american_theta=american_theta,\n",
    "        cv_delta=cv_delta,\n",
    "        cv_gamma=cv_gamma_final,\n",
    "        cv_theta=cv_theta,\n",
    "        gamma_scheme=gamma_scheme,\n",
    "        steps_requested=steps,\n",
    "        extras=extras,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def crr_tree_greeks_on_grids(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    gamma_scheme: str = 'central',\n",
    ") -> Outputs:\n",
    "    return binomial_tree_greeks_on_grids(option, S0, K, r, q, sigma, T, steps=steps, method='crr', gamma_scheme=gamma_scheme)\n",
    "\n",
    "def lr_tree_greeks_on_grids(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    gamma_scheme: str = 'central',\n",
    ") -> Outputs:\n",
    "    return binomial_tree_greeks_on_grids(option, S0, K, r, q, sigma, T, steps=steps, method='lr', gamma_scheme=gamma_scheme)\n",
    "\n",
    "def tian_tree_greeks_on_grids(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    gamma_scheme: str = 'central',\n",
    ") -> Outputs:\n",
    "    return binomial_tree_greeks_on_grids(option, S0, K, r, q, sigma, T, steps=steps, method='tian', gamma_scheme=gamma_scheme)\n",
    "\n",
    "def tree12(\n",
    "    option: OptionType,\n",
    "    S0: float,\n",
    "    K: float,\n",
    "    r: float,\n",
    "    q: float,\n",
    "    sigma: float,\n",
    "    T: float,\n",
    "    *,\n",
    "    steps: int,\n",
    "    method: str = 'crr',\n",
    "    gamma_scheme: str = 'central',\n",
    "):\n",
    "    \"\"\"Return the 12 core quantities required by the assignment.\"\"\"\n",
    "    out = binomial_tree_greeks_on_grids(\n",
    "        option,\n",
    "        S0,\n",
    "        K,\n",
    "        r,\n",
    "        q,\n",
    "        sigma,\n",
    "        T,\n",
    "        steps=steps,\n",
    "        method=method,\n",
    "        gamma_scheme=gamma_scheme,\n",
    "    )\n",
    "    return (\n",
    "        out.bs_euro_value,\n",
    "        out.bs_euro_delta,\n",
    "        out.bs_euro_gamma,\n",
    "        out.euro_value,\n",
    "        out.euro_delta,\n",
    "        out.euro_gamma,\n",
    "        out.american_value,\n",
    "        out.american_delta,\n",
    "        out.american_gamma,\n",
    "        out.cv_value,\n",
    "        out.cv_delta,\n",
    "        out.cv_gamma,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d2cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:45.444982Z",
     "iopub.status.busy": "2025-11-10T22:01:45.444767Z",
     "iopub.status.idle": "2025-11-10T22:01:45.472988Z",
     "shell.execute_reply": "2025-11-10T22:01:45.471444Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = 'put'\n",
    "S0, r, q, sigma, T = 50.0, 0.1, 0.02, 0.3, 0.1\n",
    "sample_methods = [\n",
    "    ('CRR (central Gamma)', 'crr', 'central'),\n",
    "    ('CRR (multi-layer Gamma)', 'crr', 'multi-layer'),\n",
    "    ('Leisen–Reimer', 'lr', 'central'),\n",
    "    ('Tian', 'tian', 'central'),\n",
    "]\n",
    "rows = []\n",
    "for label, method, gamma_scheme in sample_methods:\n",
    "    out = binomial_tree_greeks_on_grids(opt, S0, 50.0, r, q, sigma, T, steps=25, method=method, gamma_scheme=gamma_scheme)\n",
    "    rows.append({\n",
    "        'Method': label,\n",
    "        'Steps used': out.steps_used,\n",
    "        'American V': out.american_value,\n",
    "        'American Delta': out.american_delta,\n",
    "        'American Gamma': out.american_gamma,\n",
    "        'CV V': out.cv_value,\n",
    "        'CV Delta': out.cv_delta,\n",
    "        'CV Gamma': out.cv_gamma,\n",
    "        'CV Theta': out.cv_theta,\n",
    "    })\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935915bd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abf20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:45.475201Z",
     "iopub.status.busy": "2025-11-10T22:01:45.474995Z",
     "iopub.status.idle": "2025-11-10T22:01:45.479879Z",
     "shell.execute_reply": "2025-11-10T22:01:45.479137Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = 'put'\n",
    "S0, r, q, sigma, T = 50.0, 0.1, 0.02, 0.3, 0.1\n",
    "strikes = [46.0, 53.0]\n",
    "bigNs = [100, 105, 110, 120]\n",
    "search_steps = range(5, 401)\n",
    "proxy_steps_mid = 1000\n",
    "proxy_steps_high = 5000\n",
    "metric_order = ['Value', 'Delta', 'Gamma', 'Theta']\n",
    "AMERICAN_ATTR = {'Value': 'american_value', 'Delta': 'american_delta', 'Gamma': 'american_gamma', 'Theta': 'american_theta'}\n",
    "CV_ATTR = {'Value': 'cv_value', 'Delta': 'cv_delta', 'Gamma': 'cv_gamma', 'Theta': 'cv_theta'}\n",
    "BS_ATTR = {'Value': 'bs_euro_value', 'Delta': 'bs_euro_delta', 'Gamma': 'bs_euro_gamma', 'Theta': 'bs_euro_theta'}\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_output(method: str, gamma_scheme: str, steps: int, strike: float) -> Outputs:\n",
    "    return binomial_tree_greeks_on_grids(opt, S0, strike, r, q, sigma, T, steps=steps, method=method, gamma_scheme=gamma_scheme)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbffc2",
   "metadata": {},
   "source": [
    "## Higher-precision Gamma benchmark and smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd7400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:45.482162Z",
     "iopub.status.busy": "2025-11-10T22:01:45.481972Z",
     "iopub.status.idle": "2025-11-10T22:01:49.437229Z",
     "shell.execute_reply": "2025-11-10T22:01:49.436276Z"
    }
   },
   "outputs": [],
   "source": [
    "proxy_rows = []\n",
    "for steps in (proxy_steps_mid, proxy_steps_high):\n",
    "    for K in strikes:\n",
    "        out = get_output('crr', 'central', steps, K)\n",
    "        proxy_rows.append({\n",
    "            'Steps': steps,\n",
    "            'Strike': K,\n",
    "            'CV Value': out.cv_value,\n",
    "            'CV Delta': out.cv_delta,\n",
    "            'CV Gamma': out.cv_gamma,\n",
    "            'CV Theta': out.cv_theta\n",
    "        })\n",
    "proxy_df = pd.DataFrame(proxy_rows)\n",
    "baseline = {K: get_output('crr', 'central', proxy_steps_high, K) for K in strikes}\n",
    "proxy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d90ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:49.439570Z",
     "iopub.status.busy": "2025-11-10T22:01:49.439398Z",
     "iopub.status.idle": "2025-11-10T22:01:49.453578Z",
     "shell.execute_reply": "2025-11-10T22:01:49.452475Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma_cmp = (proxy_df.pivot(index='Strike', columns='Steps', values='CV Gamma')\n",
    "              .rename(columns={proxy_steps_mid: f'{proxy_steps_mid} step Gamma', proxy_steps_high: f'{proxy_steps_high} step Gamma'}))\n",
    "gamma_cmp['Abs DeltaGamma'] = (gamma_cmp.iloc[:, 1] - gamma_cmp.iloc[:, 0]).abs()\n",
    "gamma_cmp['Rel DeltaGamma'] = gamma_cmp['Abs DeltaGamma'] / gamma_cmp.iloc[:, 1] * 100\n",
    "gamma_cmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d49e80",
   "metadata": {},
   "source": [
    "Updated big-tree errors against the refined proxy (5000-step CV Americans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:49.457067Z",
     "iopub.status.busy": "2025-11-10T22:01:49.456770Z",
     "iopub.status.idle": "2025-11-10T22:01:49.534920Z",
     "shell.execute_reply": "2025-11-10T22:01:49.534183Z"
    }
   },
   "outputs": [],
   "source": [
    "big_tree_records = []\n",
    "for K in strikes:\n",
    "    ref = baseline[K]\n",
    "    for N in bigNs:\n",
    "        out_central = get_output('crr', 'central', N, K)\n",
    "        record = {\n",
    "            'Strike': K,\n",
    "            'Steps': out_central.steps_used,\n",
    "            'American |DeltaV|': abs(out_central.american_value - ref.cv_value),\n",
    "            'American |DeltaDelta|': abs(out_central.american_delta - ref.cv_delta),\n",
    "            'American |DeltaGamma|': abs(out_central.american_gamma - ref.cv_gamma),\n",
    "            'CV |DeltaV|': abs(out_central.cv_value - ref.cv_value),\n",
    "            'CV |DeltaDelta|': abs(out_central.cv_delta - ref.cv_delta),\n",
    "            'CV |DeltaGamma|': abs(out_central.cv_gamma - ref.cv_gamma)\n",
    "        }\n",
    "        big_tree_records.append(record)\n",
    "big_tree_df = pd.DataFrame(big_tree_records)\n",
    "big_tree_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dbf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:49.537832Z",
     "iopub.status.busy": "2025-11-10T22:01:49.537515Z",
     "iopub.status.idle": "2025-11-10T22:01:49.552789Z",
     "shell.execute_reply": "2025-11-10T22:01:49.551406Z"
    }
   },
   "outputs": [],
   "source": [
    "E_V_H = big_tree_df.groupby('Strike')['American |DeltaV|'].mean()\n",
    "E_delta_H = big_tree_df.groupby('Strike')['American |DeltaDelta|'].mean()\n",
    "E_gamma_H = big_tree_df.groupby('Strike')['American |DeltaGamma|'].mean()\n",
    "display(E_V_H, E_delta_H, E_gamma_H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039560c",
   "metadata": {},
   "source": [
    "### CV savings factors with refined Gamma benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a47796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:49.555551Z",
     "iopub.status.busy": "2025-11-10T22:01:49.555298Z",
     "iopub.status.idle": "2025-11-10T22:01:49.794070Z",
     "shell.execute_reply": "2025-11-10T22:01:49.792372Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_min_steps_for_metric(strike: float, metric: str, target_error: float, *,\n",
    "                              method: str = 'crr', gamma_scheme: str = 'central', steps_cap: int = 400) -> Tuple[int, int]:\n",
    "    for steps in range(5, steps_cap + 1):\n",
    "        out = get_output(method, gamma_scheme, steps, strike)\n",
    "        ref = baseline[strike]\n",
    "        attr = CV_ATTR[metric]\n",
    "        err = abs(getattr(out, attr) - getattr(ref, attr))\n",
    "        if err <= target_error:\n",
    "            return steps, out.steps_used\n",
    "    return steps_cap, get_output(method, gamma_scheme, steps_cap, strike).steps_used\n",
    "\n",
    "cv_savings_rows = []\n",
    "error_cols = {'Value': 'American |DeltaV|', 'Delta': 'American |DeltaDelta|', 'Gamma': 'American |DeltaGamma|'}\n",
    "for gamma_scheme in ('central', 'multi-layer'):\n",
    "    for K in strikes:\n",
    "        ref = baseline[K]\n",
    "        target_errors = {\n",
    "            metric: big_tree_df.loc[big_tree_df['Strike'] == K, error_cols[metric]].mean()\n",
    "            for metric in ('Value', 'Delta', 'Gamma')\n",
    "        }\n",
    "        for metric, target in target_errors.items():\n",
    "            steps_req, steps_used = find_min_steps_for_metric(K, metric, target, method='crr', gamma_scheme=gamma_scheme)\n",
    "            cv_savings_rows.append({\n",
    "                'Gamma scheme': 'central' if gamma_scheme == 'central' else 'multi-layer',\n",
    "                'Strike': K,\n",
    "                'Metric': metric,\n",
    "                'Target error': target,\n",
    "                'Min CV steps': steps_req,\n",
    "                'Steps used': steps_used,\n",
    "                'Mean big-tree steps': np.mean(bigNs),\n",
    "                'Savings factor': np.mean(bigNs) / steps_req\n",
    "            })\n",
    "cv_savings_df = pd.DataFrame(cv_savings_rows)\n",
    "cv_savings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb45950",
   "metadata": {},
   "source": [
    "### Gamma convergence - central vs multi-layer smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc72275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:49.796531Z",
     "iopub.status.busy": "2025-11-10T22:01:49.796205Z",
     "iopub.status.idle": "2025-11-10T22:01:51.694848Z",
     "shell.execute_reply": "2025-11-10T22:01:51.694435Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma_conv_rows = []\n",
    "for scheme in ('central', 'multi-layer'):\n",
    "    for K in strikes:\n",
    "        ref = baseline[K]\n",
    "        for steps in range(10, 321, 10):\n",
    "            out = get_output('crr', scheme, steps, K)\n",
    "            gamma_amer_err = abs(out.american_gamma - ref.cv_gamma)\n",
    "            gamma_cv_err = abs(out.cv_gamma - ref.cv_gamma)\n",
    "            gamma_conv_rows.append({\n",
    "                'Gamma scheme': 'central' if scheme == 'central' else 'multi-layer',\n",
    "                'Strike': K,\n",
    "                'Steps': out.steps_used,\n",
    "                'American Gamma error': gamma_amer_err,\n",
    "                'CV Gamma error': gamma_cv_err\n",
    "            })\n",
    "gamma_conv_df = pd.DataFrame(gamma_conv_rows)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "for ax, col in zip(axes, ['American Gamma error', 'CV Gamma error']):\n",
    "    sns.lineplot(data=gamma_conv_df, x='Steps', y=col, hue='Gamma scheme', style='Strike', marker='o', ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(col)\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gamma_conv_summary = (gamma_conv_df\n",
    "                       .groupby(['Gamma scheme', 'Strike'])[['American Gamma error', 'CV Gamma error']]\n",
    "                       .agg(['mean', 'std']))\n",
    "gamma_conv_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56ad2c",
   "metadata": {},
   "source": [
    "## Alternate trees and acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e0737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:01:51.697907Z",
     "iopub.status.busy": "2025-11-10T22:01:51.697702Z",
     "iopub.status.idle": "2025-11-10T22:02:23.134211Z",
     "shell.execute_reply": "2025-11-10T22:02:23.133465Z"
    }
   },
   "outputs": [],
   "source": [
    "method_configs = [\n",
    "    ('CRR (central Gamma)', 'crr', 'central'),\n",
    "    ('CRR (multi-layer Gamma)', 'crr', 'multi-layer'),\n",
    "    ('Leisen–Reimer', 'lr', 'central'),\n",
    "    ('Tian', 'tian', 'central'),\n",
    "]\n",
    "\n",
    "def build_method_grid(label: str, method: str, gamma_scheme: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for steps in search_steps:\n",
    "        for K in strikes:\n",
    "            out = get_output(method, gamma_scheme, steps, K)\n",
    "            ref = baseline[K]\n",
    "            rows.append({\n",
    "                'Label': label,\n",
    "                'Method': method,\n",
    "                'Gamma scheme': gamma_scheme,\n",
    "                'Strike': K,\n",
    "                'Steps requested': steps,\n",
    "                'Steps used': out.steps_used,\n",
    "                'American |DeltaV|': abs(out.american_value - ref.cv_value),\n",
    "                'American |DeltaDelta|': abs(out.american_delta - ref.cv_delta),\n",
    "                'American |DeltaGamma|': abs(out.american_gamma - ref.cv_gamma),\n",
    "                'CV |DeltaV|': abs(out.cv_value - ref.cv_value),\n",
    "                'CV |DeltaDelta|': abs(out.cv_delta - ref.cv_delta),\n",
    "                'CV |DeltaGamma|': abs(out.cv_gamma - ref.cv_gamma)\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "method_grids = {label: build_method_grid(label, method, gamma_scheme) for label, method, gamma_scheme in method_configs}\n",
    "combined_method_df = pd.concat(method_grids.values(), ignore_index=True)\n",
    "combined_method_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9399b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:02:23.137201Z",
     "iopub.status.busy": "2025-11-10T22:02:23.136805Z",
     "iopub.status.idle": "2025-11-10T22:02:23.164896Z",
     "shell.execute_reply": "2025-11-10T22:02:23.163797Z"
    }
   },
   "outputs": [],
   "source": [
    "target_cv_errors = {}\n",
    "for K in strikes:\n",
    "    out_100 = method_grids['CRR (central Gamma)']\n",
    "    mask = (out_100['Strike'] == K) & (out_100['Steps used'] == 100)\n",
    "    row = out_100.loc[mask].iloc[0]\n",
    "    target_cv_errors[K] = {\n",
    "        'Value': row['CV |DeltaV|'],\n",
    "        'Delta': row['CV |DeltaDelta|'],\n",
    "        'Gamma': row['CV |DeltaGamma|']\n",
    "    }\n",
    "\n",
    "match_rows = []\n",
    "for label, grid in method_grids.items():\n",
    "    for K in strikes:\n",
    "        targets = target_cv_errors[K]\n",
    "        for metric, col in zip(('Value', 'Delta', 'Gamma'), ('CV |DeltaV|', 'CV |DeltaDelta|', 'CV |DeltaGamma|')):\n",
    "            subset = grid[(grid['Strike'] == K) & (grid[col] <= targets[metric])]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            best = subset.sort_values('Steps used', kind='stable').iloc[0]\n",
    "            match_rows.append({\n",
    "                'Method': label,\n",
    "                'Strike': K,\n",
    "                'Metric': metric,\n",
    "                'Target error': targets[metric],\n",
    "                'Steps requested': best['Steps requested'],\n",
    "                'Steps used': best['Steps used'],\n",
    "                'Savings vs 100-step CRR': 100 / best['Steps used']\n",
    "            })\n",
    "match_df = pd.DataFrame(match_rows)\n",
    "match_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea460da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:02:23.166819Z",
     "iopub.status.busy": "2025-11-10T22:02:23.166643Z",
     "iopub.status.idle": "2025-11-10T22:02:23.176413Z",
     "shell.execute_reply": "2025-11-10T22:02:23.175819Z"
    }
   },
   "outputs": [],
   "source": [
    "method_summary = (match_df.groupby(['Method', 'Metric'])\n",
    "                  [['Steps used', 'Savings vs 100-step CRR']]\n",
    "                  .mean()\n",
    "                  .rename(columns={'Steps used': 'Mean steps used',\n",
    "                                   'Savings vs 100-step CRR': 'Mean savings factor'})\n",
    "                  .reset_index())\n",
    "method_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232623d",
   "metadata": {},
   "source": [
    "### Richardson extrapolation vs CV correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc581a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:02:23.179122Z",
     "iopub.status.busy": "2025-11-10T22:02:23.178766Z",
     "iopub.status.idle": "2025-11-10T22:02:23.205469Z",
     "shell.execute_reply": "2025-11-10T22:02:23.204618Z"
    }
   },
   "outputs": [],
   "source": [
    "richardson_rows = []\n",
    "for K in strikes:\n",
    "    ref = baseline[K]\n",
    "    for N in (10, 20, 40, 80, 160):\n",
    "        out_N = get_output('crr', 'central', N, K)\n",
    "        out_2N = get_output('crr', 'central', 2 * N, K)\n",
    "        delta_r = 2 * out_2N.american_delta - out_N.american_delta\n",
    "        gamma_r = 2 * out_2N.american_gamma - out_N.american_gamma\n",
    "        cost_r = out_N.steps_used ** 2 + out_2N.steps_used ** 2\n",
    "        cost_cv = out_N.steps_used ** 2\n",
    "        cv_delta_err = abs(out_N.cv_delta - ref.cv_delta)\n",
    "        cv_gamma_err = abs(out_N.cv_gamma - ref.cv_gamma)\n",
    "        richardson_rows.extend([\n",
    "            {'Strike': K, 'N': N, 'Approach': 'CV', 'Metric': 'Delta', 'Abs error': cv_delta_err, 'Cost proxy': cost_cv},\n",
    "            {'Strike': K, 'N': N, 'Approach': 'CV', 'Metric': 'Gamma', 'Abs error': cv_gamma_err, 'Cost proxy': cost_cv},\n",
    "            {'Strike': K, 'N': N, 'Approach': 'Richardson', 'Metric': 'Delta', 'Abs error': abs(delta_r - ref.cv_delta), 'Cost proxy': cost_r},\n",
    "            {'Strike': K, 'N': N, 'Approach': 'Richardson', 'Metric': 'Gamma', 'Abs error': abs(gamma_r - ref.cv_gamma), 'Cost proxy': cost_r},\n",
    "        ])\n",
    "richardson_df = pd.DataFrame(richardson_rows)\n",
    "richardson_df['Error per cost'] = richardson_df['Abs error'] / richardson_df['Cost proxy']\n",
    "richardson_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b9133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T22:02:23.207869Z",
     "iopub.status.busy": "2025-11-10T22:02:23.207659Z",
     "iopub.status.idle": "2025-11-10T22:02:23.216572Z",
     "shell.execute_reply": "2025-11-10T22:02:23.216009Z"
    }
   },
   "outputs": [],
   "source": [
    "richardson_summary = (richardson_df.groupby(['Approach', 'Metric'])\n",
    "                      [['Abs error', 'Error per cost']]\n",
    "                      .mean()\n",
    "                      .reset_index())\n",
    "richardson_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab086c05",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "\n",
    "* **Gamma stability:** Multi-layer smoothing markedly reduces oscillations in Gamma, yielding lower variance in the error curves while converging faster towards the refined 5000-step proxy. Leisen–Reimer delivers comparable Gamma accuracy to the smoothed CRR tree but with a modest increase in effective steps (odd-lattice requirement).\n",
    "* **Alternate lattices vs CV:** When matching the 100-step CRR error tolerance, CV-corrected CRR with smoothed Gamma and the Leisen–Reimer tree reach the target with roughly half the nodes required by the plain CRR lattice. Tian’s third-moment matching performs better on values but shows slightly slower Gamma convergence. Richardson extrapolation improves raw Greeks yet still lags the CV approach once computational effort is normalised.\n",
    "* **Exercise boundary:** Increasing the step count produces a smooth, monotone early-exercise frontier, and the boundary stabilisation coincides with the improvements observed in Delta and Gamma near the exercise region. This supports using smoothed Gamma when accurate hedging around the boundary is critical.\n",
    "* **Market-regime robustness:** Savings factors for CV adjustments stay above ~2× across $T \\in \\{0.05, 0.1, 0.25\\}$ and $\\sigma \\in \\{0.2, 0.3, 0.5\\}$. The benefit strengthens slightly with higher volatility or longer maturity as raw tree errors deteriorate faster.\n",
    "* **Production guidance:** Use multi-layer Gamma smoothing together with the analytic Theta control variate for CRR Americans. Resort to Leisen–Reimer when ultra-low Gamma noise is needed or when strike-to-spot ratios are extreme; Tian can complement CRR for value convergence. Richardson extrapolation is best kept as a diagnostic as its cost-weighted accuracy trails the CV methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cdd063",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

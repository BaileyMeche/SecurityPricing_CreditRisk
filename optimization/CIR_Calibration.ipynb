{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a13078",
   "metadata": {},
   "source": [
    "# CIR Calibration with Steepest Descent, Newton, and Gauss–Newton\n",
    "\n",
    "This notebook calibrates a Cox–Ingersoll–Ross (CIR) term structure model to U.S. Treasury yield data using three optimization algorithms: steepest descent, Newton, and Gauss–Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import textwrap\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e4f6a",
   "metadata": {},
   "source": [
    "\n",
    "### Treasury bond data file format (tbonds.txt)\n",
    "\n",
    "* The first non-empty line is a header:\n",
    "\n",
    "```\n",
    "w | t    1/12 0.25  0.5    1    3    5    7   10   20   30\n",
    "```\n",
    "\n",
    "  * \"w\" is a week label, \"t\" labels maturities.\n",
    "  * The maturities (time to maturity in years) are: (1/12, 0.25, 0.5, 1, 3, 5, 7, 10, 20, 30).\n",
    "\n",
    "* Remaining lines give one row per week, with blank lines between:\n",
    "\n",
    "```\n",
    "09/12/24 5.18 5.06 4.68 4.09 3.47 3.47 3.57 3.68 4.07 4.00\n",
    "\n",
    "09/19/24 4.89 4.80 4.46 3.93 3.47 3.49 3.60 3.73 4.11 4.06\n",
    "```\n",
    "\n",
    "  * First token: date string.\n",
    "  * Next 10 tokens: yields in percent for the 10 maturities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_tbonds_file(filename=\"tbonds.txt\"):\n",
    "    maturities = []\n",
    "    dates = []\n",
    "    rates_rows = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Filter out lines that are completely empty (or whitespace only)\n",
    "    non_empty_lines = [ln.strip() for ln in lines if ln.strip() != \"\"]\n",
    "\n",
    "    if len(non_empty_lines) == 0:\n",
    "        raise ValueError(\"File appears empty or only whitespace\")\n",
    "\n",
    "    # First non-empty line is header\n",
    "    header_line = non_empty_lines[0]\n",
    "    header_line = header_line.replace(\"|\", \" \")\n",
    "    header_tokens = header_line.split()\n",
    "\n",
    "    # header_tokens should look like:\n",
    "    # [\"w\", \"t\", \"1/12\", \"0.25\", \"0.5\", \"1\", \"3\", \"5\", \"7\", \"10\", \"20\", \"30\"]\n",
    "    if len(header_tokens) < 3:\n",
    "        raise ValueError(\"Header line does not contain maturities\")\n",
    "\n",
    "    maturity_tokens = header_tokens[2:]  # skip \"w\" and \"t\"\n",
    "\n",
    "    for tok in maturity_tokens:\n",
    "        if \"/\" in tok:\n",
    "            num, den = tok.split(\"/\")\n",
    "            maturities.append(float(num) / float(den))\n",
    "        else:\n",
    "            maturities.append(float(tok))\n",
    "\n",
    "    # Remaining non-empty lines are data rows\n",
    "    for line in non_empty_lines[1:]:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "        date_str = tokens[0]\n",
    "        rates = [float(x) for x in tokens[1:]]\n",
    "        dates.append(date_str)\n",
    "        rates_rows.append(rates)\n",
    "\n",
    "    t_vec = np.array(maturities, dtype=float)           # shape (M,)\n",
    "    R = np.array(rates_rows, dtype=float)               # shape (W, M)\n",
    "    return t_vec, dates, R\n",
    "\n",
    "\n",
    "t_vec, dates, R = read_tbonds_file(\"tbonds.txt\")\n",
    "print(\"Maturities:\", t_vec)\n",
    "print(\"Dates:\", dates)\n",
    "print(\"R shape:\", R.shape)\n",
    "print(\"First row of rates:\", R[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50b8a7",
   "metadata": {},
   "source": [
    "\n",
    "### CIR zero-coupon bond and yield formulas\n",
    "We use the Cox–Ingersoll–Ross (CIR) model under no arbitrage, where the price of a zero-coupon bond is\n",
    "\\[\n",
    "P(r,t;a,b,\\sigma) = A(t;a,b,\\sigma)\\, e^{-B(t;a,\\sigma)\\,r}\n",
    "\\]\n",
    "with\n",
    "\\[\n",
    "h(a,\\sigma) = \\sqrt{a^2 + 2\\sigma^2},\n",
    "\\]\n",
    "\\[\n",
    "A(t;a,b,\\sigma) =\n",
    "\\left[\n",
    "\f",
    "rac{2 h \\exp\\left(\tfrac{a+h}{2} t\r",
    "ight)}\n",
    "{2h + (a+h)(e^{h t}-1)}\n",
    "\r",
    "ight]^{\f",
    "rac{2ab}{\\sigma^2}},\n",
    "\\quad\n",
    "B(t;a,\\sigma) =\n",
    "\f",
    "rac{2(e^{h t}-1)}{2h + (a+h)(e^{h t}-1)}.\n",
    "\\]\n",
    "The continuously-compounded yield (rate of return in percent) is\n",
    "\\[\n",
    "R_{\text{model}}(t; r,a,b,\\sigma)\n",
    "= -\f",
    "rac{\\log P(r,t;a,b,\\sigma)}{t} \times 100.\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cir_h(a, sigma):\n",
    "    return math.sqrt(a * a + 2.0 * sigma * sigma)\n",
    "\n",
    "\n",
    "def cir_A_B(t, a, b, sigma):\n",
    "    \"\"\"\n",
    "    Return (A(t; a,b,sigma), B(t; a,sigma)) for the CIR formula.\n",
    "    \"\"\"\n",
    "    h = cir_h(a, sigma)\n",
    "    exp_ht = math.exp(h * t)\n",
    "    numerator = 2.0 * h * math.exp((a + h) * t / 2.0)\n",
    "    denom = 2.0 * h + (a + h) * (exp_ht - 1.0)\n",
    "    C = numerator / denom\n",
    "    q = 2.0 * a * b / (sigma * sigma)\n",
    "    A = C ** q\n",
    "    B = 2.0 * (exp_ht - 1.0) / denom\n",
    "    return A, B\n",
    "\n",
    "\n",
    "def cir_price(r, t, a, b, sigma):\n",
    "    A, B = cir_A_B(t, a, b, sigma)\n",
    "    return A * math.exp(-B * r)\n",
    "\n",
    "\n",
    "def cir_yield_percent(r, t, a, b, sigma):\n",
    "    \"\"\"\n",
    "    r, a, b, sigma are given as decimal rates,\n",
    "    but the returned yield is in percent (%),\n",
    "    to match the data units in tbonds.txt.\n",
    "    \"\"\"\n",
    "    P = cir_price(r, t, a, b, sigma)\n",
    "    return - (math.log(P) / t) * 100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73d4ae",
   "metadata": {},
   "source": [
    "\n",
    "### Weekly nonlinear least squares formulation\n",
    "For a given week (w), we have maturities (t_j) and observed yields (R_{w,j}^{\text{obs}}) (in percent, from the dataset).\n",
    "We collect the parameters in \\(x = (r, a, b, \\sigma)^\top\\). The model yield is\n",
    "\\[\n",
    "R_{\text{model}}(t_j; x) = R_{\text{model}}(t_j; r,a,b,\\sigma).\n",
    "\\]\n",
    "Residuals and objective:\n",
    "\\[\n",
    "f_j(x) = R_{\text{model}}(t_j; x) - R_{w,j}^{\text{obs}}, \\quad\n",
    "\u000b",
    "arphi(x) = \tfrac12 \\sum_{j=1}^M f_j(x)^2.\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bec940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def residuals_week(x, t_vec, R_obs_row):\n",
    "    \"\"\"\n",
    "    x = [r, a, b, sigma]\n",
    "    t_vec: shape (M,)\n",
    "    R_obs_row: shape (M,) observed yields in percent\n",
    "    \"\"\"\n",
    "    r, a, b, sigma = x\n",
    "    M = len(t_vec)\n",
    "    F = np.zeros(M, dtype=float)\n",
    "    for j in range(M):\n",
    "        t = t_vec[j]\n",
    "        R_model = cir_yield_percent(r, t, a, b, sigma)\n",
    "        F[j] = R_model - R_obs_row[j]\n",
    "    return F\n",
    "\n",
    "\n",
    "def objective_week(x, t_vec, R_obs_row):\n",
    "    F = residuals_week(x, t_vec, R_obs_row)\n",
    "    return 0.5 * np.dot(F, F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aedd8c",
   "metadata": {},
   "source": [
    "\n",
    "### Finite-difference Jacobian, gradient, and Gauss–Newton Hessian (weekly)\n",
    "For least squares \\(\u000b",
    "arphi(x) = \tfrac12 |F(x)|^2\\) we use\n",
    "\\(\n",
    "abla \u000b",
    "arphi(x) = J_F(x)^T F(x)\\) and the Gauss–Newton approximation\n",
    "\\(\n",
    "abla^2 \u000b",
    "arphi(x) \u0007pprox J_F(x)^T J_F(x)\\). We compute \\(J_F(x)\\) via forward finite differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67361746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jacobian_fd_week(x, t_vec, R_obs_row, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Finite-difference Jacobian for the residuals F(x) for a single week.\n",
    "    J has shape (M, 4).\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    F0 = residuals_week(x, t_vec, R_obs_row)\n",
    "    M = len(F0)\n",
    "    n = len(x)\n",
    "    J = np.zeros((M, n), dtype=float)\n",
    "\n",
    "    for k in range(n):\n",
    "        x_perturbed = x.copy()\n",
    "        delta = eps * max(1.0, abs(x[k]))\n",
    "        x_perturbed[k] = x[k] + delta\n",
    "        Fk = residuals_week(x_perturbed, t_vec, R_obs_row)\n",
    "        J[:, k] = (Fk - F0) / delta\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def grad_week(x, t_vec, R_obs_row, eps=1e-6):\n",
    "    F = residuals_week(x, t_vec, R_obs_row)\n",
    "    J = jacobian_fd_week(x, t_vec, R_obs_row, eps=eps)\n",
    "    return J.T @ F\n",
    "\n",
    "\n",
    "def hess_gauss_newton_week(x, t_vec, R_obs_row, eps=1e-6):\n",
    "    J = jacobian_fd_week(x, t_vec, R_obs_row, eps=eps)\n",
    "    return J.T @ J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771286f",
   "metadata": {},
   "source": [
    "\n",
    "### Backtracking line search (Armijo)\n",
    "All three methods use backtracking to select step lengths. Starting from \\(\u0007lpha_0\\), shrink by \\(\r",
    "ho\\) until the Armijo condition\n",
    "\\( \u000b",
    "arphi(x + \u0007lpha p) \\le \u000b",
    "arphi(x) + c \u0007lpha \n",
    "abla \u000b",
    "arphi(x)^T p \\) holds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7215b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backtracking_line_search_week(x, p, t_vec, R_obs_row,\n",
    "                                  alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                  eps=1e-6):\n",
    "    \"\"\"\n",
    "    Backtracking line search for the weekly objective.\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    p = np.array(p, dtype=float)\n",
    "\n",
    "    f_x = objective_week(x, t_vec, R_obs_row)\n",
    "    g_x = grad_week(x, t_vec, R_obs_row, eps=eps)\n",
    "    alpha = alpha_init\n",
    "\n",
    "    while True:\n",
    "        x_new = x + alpha * p\n",
    "        f_new = objective_week(x_new, t_vec, R_obs_row)\n",
    "        if f_new <= f_x + c * alpha * np.dot(g_x, p):\n",
    "            break\n",
    "        alpha *= rho\n",
    "        if alpha < 1e-10:\n",
    "            break\n",
    "\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6fe2f",
   "metadata": {},
   "source": [
    "\n",
    "### Optimization algorithms for a single week\n",
    "We implement steepest descent, Newton (using the Gauss–Newton Hessian for stability), and Gauss–Newton with optional line search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def steepest_descent_week(x0, t_vec, R_obs_row,\n",
    "                          max_iters=1000, tol=1e-6, eps=1e-6,\n",
    "                          verbose=False):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    for k in range(max_iters):\n",
    "        g = grad_week(x, t_vec, R_obs_row, eps=eps)\n",
    "        ng = np.linalg.norm(g)\n",
    "        if verbose and k % 50 == 0:\n",
    "            print(f\"[SD] iter {k}, f={objective_week(x, t_vec, R_obs_row):.6e}, ||grad||={ng:.6e}\")\n",
    "        if ng < tol:\n",
    "            break\n",
    "\n",
    "        p = -g\n",
    "        alpha = backtracking_line_search_week(x, p, t_vec, R_obs_row,\n",
    "                                              alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                              eps=eps)\n",
    "        x = x + alpha * p\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cdb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def newton_week(x0, t_vec, R_obs_row,\n",
    "                max_iters=50, tol=1e-8, eps=1e-6,\n",
    "                use_gauss_newton_hessian=True,\n",
    "                verbose=False):\n",
    "    x = np.array(x0, dtype=float)\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        g = grad_week(x, t_vec, R_obs_row, eps=eps)\n",
    "        ng = np.linalg.norm(g)\n",
    "        if verbose:\n",
    "            print(f\"[Newton] iter {k}, f={objective_week(x, t_vec, R_obs_row):.6e}, ||grad||={ng:.6e}\")\n",
    "        if ng < tol:\n",
    "            break\n",
    "\n",
    "        if use_gauss_newton_hessian:\n",
    "            H = hess_gauss_newton_week(x, t_vec, R_obs_row, eps=eps)\n",
    "        else:\n",
    "            H = hess_gauss_newton_week(x, t_vec, R_obs_row, eps=eps)\n",
    "\n",
    "        try:\n",
    "            p = np.linalg.solve(H, -g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            H_reg = H + 1e-6 * np.eye(len(x))\n",
    "            p = np.linalg.solve(H_reg, -g)\n",
    "\n",
    "        alpha = backtracking_line_search_week(x, p, t_vec, R_obs_row,\n",
    "                                              alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                              eps=eps)\n",
    "        x = x + alpha * p\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfcce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gauss_newton_week(x0, t_vec, R_obs_row,\n",
    "                      max_iters=50, tol=1e-8, eps=1e-6,\n",
    "                      use_line_search=True,\n",
    "                      verbose=False):\n",
    "    x = np.array(x0, dtype=float)\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        F = residuals_week(x, t_vec, R_obs_row)\n",
    "        J = jacobian_fd_week(x, t_vec, R_obs_row, eps=eps)\n",
    "        g = J.T @ F\n",
    "        ng = np.linalg.norm(g)\n",
    "        if verbose:\n",
    "            print(f\"[GN] iter {k}, f={0.5 * np.dot(F, F):.6e}, ||J^T F||={ng:.6e}\")\n",
    "        if ng < tol:\n",
    "            break\n",
    "\n",
    "        H_gn = J.T @ J\n",
    "        try:\n",
    "            p = np.linalg.solve(H_gn, -g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            H_reg = H_gn + 1e-6 * np.eye(len(x))\n",
    "            p = np.linalg.solve(H_reg, -g)\n",
    "\n",
    "        if use_line_search:\n",
    "            alpha = backtracking_line_search_week(x, p, t_vec, R_obs_row,\n",
    "                                                  alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                                  eps=eps)\n",
    "        else:\n",
    "            alpha = 1.0\n",
    "\n",
    "        x = x + alpha * p\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf69260",
   "metadata": {},
   "source": [
    "\n",
    "## Part (1): Weekly calibration (r_w, a_w, b_w, \\sigma_w)\n",
    "For each week we minimize\n",
    "\\(\u000b",
    "arphi_w(r,a,b,\\sigma) = \tfrac12 \\sum_j (R_{\text{model}}(t_j; r,a,b,\\sigma) - R_{w,j}^{\text{obs}})^2\\)\n",
    "using the three optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c03039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W, M = R.shape\n",
    "print(\"Number of weeks:\", W, \"Number of maturities:\", M)\n",
    "\n",
    "\n",
    "def compute_sse_rmse_week(x, t_vec, R_obs_row):\n",
    "    F = residuals_week(x, t_vec, R_obs_row)\n",
    "    sse = np.dot(F, F)\n",
    "    rmse = math.sqrt(sse / len(F))\n",
    "    return sse, rmse\n",
    "\n",
    "\n",
    "results_part1 = []\n",
    "\n",
    "for w in range(W):\n",
    "    R_obs_row = R[w, :]\n",
    "    x0 = np.array([0.04, 0.5, 0.05, 0.10], dtype=float)\n",
    "\n",
    "    print(f\"\n",
    "=== Week {w} ({dates[w]}) ===\")\n",
    "    x_sd = steepest_descent_week(x0, t_vec, R_obs_row,\n",
    "                                 max_iters=1000, tol=1e-6, eps=1e-6,\n",
    "                                 verbose=False)\n",
    "    x_nt = newton_week(x0, t_vec, R_obs_row,\n",
    "                       max_iters=50, tol=1e-8, eps=1e-6,\n",
    "                       use_gauss_newton_hessian=True,\n",
    "                       verbose=False)\n",
    "    x_gn = gauss_newton_week(x0, t_vec, R_obs_row,\n",
    "                             max_iters=50, tol=1e-8, eps=1e-6,\n",
    "                             use_line_search=True,\n",
    "                             verbose=False)\n",
    "\n",
    "    for method_name, x_hat in [(\"SteepestDescent\", x_sd),\n",
    "                               (\"Newton\", x_nt),\n",
    "                               (\"GaussNewton\", x_gn)]:\n",
    "        sse, rmse = compute_sse_rmse_week(x_hat, t_vec, R_obs_row)\n",
    "        results_part1.append({\n",
    "            \"week_index\": w,\n",
    "            \"week_date\": dates[w],\n",
    "            \"method\": method_name,\n",
    "            \"params\": x_hat,\n",
    "            \"SSE\": sse,\n",
    "            \"RMSE\": rmse\n",
    "        })\n",
    "        print(f\"{method_name}: params={x_hat}, SSE={sse:.6e}, RMSE={rmse:.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1222407",
   "metadata": {},
   "source": [
    "\n",
    "### Weekly calibration discussion\n",
    "Gauss–Newton typically converges fastest thanks to the tailored Hessian approximation, while steepest descent often needs more iterations. Newton with the Gauss–Newton Hessian tends to achieve similar accuracy but may require line search regularization when the Hessian is nearly singular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b4349",
   "metadata": {},
   "source": [
    "\n",
    "## Part (2): Global model with shared (a,b,\\sigma) and week-specific r_w\n",
    "Parameters:\n",
    "\\(x = (a, b, \\sigma, r_1, \\dots, r_W)^\top\\). Residuals stack all weeks and maturities:\n",
    "\\(f_{w,j}(x) = R_{\text{model}}(t_j; r_w, a,b,\\sigma) - R_{w,j}^{\text{obs}}\\). Objective \\(\\Phi(x) = \tfrac12 \\sum_{w,j} f_{w,j}(x)^2\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19117a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def residuals_global(x, t_vec, R):\n",
    "    \"\"\"\n",
    "    x = [a, b, sigma, r_0, ..., r_{W-1}]\n",
    "    R: shape (W, M) observed yields\n",
    "    Returns a vector of length W*M (stacked by week then maturity).\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    a, b, sigma = x[0], x[1], x[2]\n",
    "    W, M = R.shape\n",
    "    F = np.zeros(W * M, dtype=float)\n",
    "    idx = 0\n",
    "    for w in range(W):\n",
    "        r_w = x[3 + w]\n",
    "        for j in range(M):\n",
    "            t = t_vec[j]\n",
    "            R_model = cir_yield_percent(r_w, t, a, b, sigma)\n",
    "            F[idx] = R_model - R[w, j]\n",
    "            idx += 1\n",
    "    return F\n",
    "\n",
    "\n",
    "def objective_global(x, t_vec, R):\n",
    "    F = residuals_global(x, t_vec, R)\n",
    "    return 0.5 * np.dot(F, F)\n",
    "\n",
    "\n",
    "def jacobian_fd_global(x, t_vec, R, eps=1e-6):\n",
    "    x = np.array(x, dtype=float)\n",
    "    F0 = residuals_global(x, t_vec, R)\n",
    "    m = len(F0)\n",
    "    n = len(x)\n",
    "    J = np.zeros((m, n), dtype=float)\n",
    "\n",
    "    for k in range(n):\n",
    "        x_perturbed = x.copy()\n",
    "        delta = eps * max(1.0, abs(x[k]))\n",
    "        x_perturbed[k] = x[k] + delta\n",
    "        Fk = residuals_global(x_perturbed, t_vec, R)\n",
    "        J[:, k] = (Fk - F0) / delta\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def grad_global(x, t_vec, R, eps=1e-6):\n",
    "    F = residuals_global(x, t_vec, R)\n",
    "    J = jacobian_fd_global(x, t_vec, R, eps=eps)\n",
    "    return J.T @ F\n",
    "\n",
    "\n",
    "def hess_gauss_newton_global(x, t_vec, R, eps=1e-6):\n",
    "    J = jacobian_fd_global(x, t_vec, R, eps=eps)\n",
    "    return J.T @ J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc421ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backtracking_line_search_global(x, p, t_vec, R,\n",
    "                                    alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                    eps=1e-6):\n",
    "    x = np.array(x, dtype=float)\n",
    "    p = np.array(p, dtype=float)\n",
    "\n",
    "    f_x = objective_global(x, t_vec, R)\n",
    "    g_x = grad_global(x, t_vec, R, eps=eps)\n",
    "    alpha = alpha_init\n",
    "\n",
    "    while True:\n",
    "        x_new = x + alpha * p\n",
    "        f_new = objective_global(x_new, t_vec, R)\n",
    "        if f_new <= f_x + c * alpha * np.dot(g_x, p):\n",
    "            break\n",
    "        alpha *= rho\n",
    "        if alpha < 1e-10:\n",
    "            break\n",
    "\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e750e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gauss_newton_global(x0, t_vec, R,\n",
    "                        max_iters=100, tol=1e-8, eps=1e-6,\n",
    "                        use_line_search=True,\n",
    "                        verbose=False):\n",
    "    x = np.array(x0, dtype=float)\n",
    "\n",
    "    for k in range(max_iters):\n",
    "        F = residuals_global(x, t_vec, R)\n",
    "        J = jacobian_fd_global(x, t_vec, R, eps=eps)\n",
    "        g = J.T @ F\n",
    "        ng = np.linalg.norm(g)\n",
    "        if verbose:\n",
    "            print(f\"[GN-global] iter {k}, f={0.5 * np.dot(F, F):.6e}, ||J^T F||={ng:.6e}\")\n",
    "        if ng < tol:\n",
    "            break\n",
    "\n",
    "        H_gn = J.T @ J\n",
    "        try:\n",
    "            p = np.linalg.solve(H_gn, -g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            H_reg = H_gn + 1e-6 * np.eye(len(x))\n",
    "            p = np.linalg.solve(H_reg, -g)\n",
    "\n",
    "        if use_line_search:\n",
    "            alpha = backtracking_line_search_global(x, p, t_vec, R,\n",
    "                                                    alpha_init=1.0, rho=0.5, c=1e-4,\n",
    "                                                    eps=eps)\n",
    "        else:\n",
    "            alpha = 1.0\n",
    "\n",
    "        x = x + alpha * p\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1066b96",
   "metadata": {},
   "source": [
    "\n",
    "### Global initial guess from weekly Gauss–Newton estimates\n",
    "We initialize (a,b,\\sigma) using the average of the weekly Gauss–Newton estimates and set each r_w to its weekly Gauss–Newton value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract weekly Gauss–Newton parameters from part 1\n",
    "\n",
    "gn_params_by_week = []\n",
    "for res in results_part1:\n",
    "    if res[\"method\"] == \"GaussNewton\":\n",
    "        gn_params_by_week.append(res[\"params\"])\n",
    "\n",
    "gn_params_by_week = np.array(gn_params_by_week)\n",
    "if gn_params_by_week.shape[0] != W:\n",
    "    print(\"Warning: mismatch in Gauss–Newton estimates; check results_part1.\")\n",
    "\n",
    "# Average a, b, sigma across weeks\n",
    "a_avg = np.mean(gn_params_by_week[:, 1])\n",
    "b_avg = np.mean(gn_params_by_week[:, 2])\n",
    "sigma_avg = np.mean(gn_params_by_week[:, 3])\n",
    "\n",
    "# Initialize r_w from weekly Gauss–Newton r's\n",
    "r_init = gn_params_by_week[:, 0]\n",
    "\n",
    "x0_global = np.concatenate([[a_avg, b_avg, sigma_avg], r_init])\n",
    "print(\"Initial global x0:\", x0_global)\n",
    "\n",
    "x_global_hat = gauss_newton_global(x0_global, t_vec, R,\n",
    "                                   max_iters=100, tol=1e-8, eps=1e-6,\n",
    "                                   use_line_search=True,\n",
    "                                   verbose=False)\n",
    "\n",
    "print(\"Fitted global parameters (a,b,sigma,r_0,...):\")\n",
    "print(x_global_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_sse_rmse_global(x, t_vec, R):\n",
    "    F = residuals_global(x, t_vec, R)\n",
    "    sse = np.dot(F, F)\n",
    "    rmse = math.sqrt(sse / len(F))\n",
    "    return sse, rmse\n",
    "\n",
    "sse_global, rmse_global = compute_sse_rmse_global(x_global_hat, t_vec, R)\n",
    "print(f\"Global model SSE={sse_global:.6e}, RMSE={rmse_global:.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f260e7",
   "metadata": {},
   "source": [
    "\n",
    "### Comparing Part (1) (weekly-flex) vs Part (2) (global shared parameters)\n",
    "We compare the fully flexible weekly model (using Gauss–Newton weekly fits) with the global shared-parameter model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate SSE/RMSE for \"weekly fully flexible\" model (using Gauss-Newton)\n",
    "sse_week_total = 0.0\n",
    "num_points = W * M\n",
    "\n",
    "for w in range(W):\n",
    "    gn_params_w = None\n",
    "    for res in results_part1:\n",
    "        if res[\"week_index\"] == w and res[\"method\"] == \"GaussNewton\":\n",
    "            gn_params_w = res[\"params\"]\n",
    "            break\n",
    "    if gn_params_w is None:\n",
    "        raise RuntimeError(f\"No Gauss–Newton result found for week {w}\")\n",
    "\n",
    "    F_w = residuals_week(gn_params_w, t_vec, R[w, :])\n",
    "    sse_w = np.dot(F_w, F_w)\n",
    "    sse_week_total += sse_w\n",
    "\n",
    "rmse_week_model = math.sqrt(sse_week_total / num_points)\n",
    "print(f\"Weekly-flex model SSE={sse_week_total:.6e}, RMSE={rmse_week_model:.6e}\")\n",
    "print(f\"Global model SSE={sse_global:.6e}, RMSE={rmse_global:.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b95ab9",
   "metadata": {},
   "source": [
    "\n",
    "The weekly-flex model has more parameters (4 per week) and will generally achieve a lower SSE/RMSE, while the global model is more parsimonious with only 3 shared parameters plus one level r_w per week. The trade-off illustrates bias–variance considerations: the flexible model fits in-sample better, while the global model enforces a common mean-reversion structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce705c",
   "metadata": {},
   "source": [
    "\n",
    "## Troubleshooting and robustness helpers\n",
    "If Newton or Gauss–Newton encounter singular matrices or fail to converge, the helpers fall back to a simpler method or add regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00499924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def robust_weekly_fit(t_vec, R_obs_row, x0=None):\n",
    "    if x0 is None:\n",
    "        x0 = np.array([0.04, 0.5, 0.05, 0.10], dtype=float)\n",
    "\n",
    "    try:\n",
    "        x_gn = gauss_newton_week(x0, t_vec, R_obs_row,\n",
    "                                 max_iters=50, tol=1e-8, eps=1e-6,\n",
    "                                 use_line_search=True,\n",
    "                                 verbose=False)\n",
    "        return x_gn, \"GaussNewton\"\n",
    "    except Exception as e:\n",
    "        print(\"Gauss–Newton failed, falling back to steepest descent:\", e)\n",
    "        x_sd = steepest_descent_week(x0, t_vec, R_obs_row,\n",
    "                                     max_iters=2000, tol=1e-6, eps=1e-6,\n",
    "                                     verbose=False)\n",
    "        return x_sd, \"SteepestDescent\"\n",
    "\n",
    "\n",
    "def robust_global_fit(x0_global, t_vec, R):\n",
    "    try:\n",
    "        return gauss_newton_global(x0_global, t_vec, R,\n",
    "                                   max_iters=100, tol=1e-8, eps=1e-6,\n",
    "                                   use_line_search=True,\n",
    "                                   verbose=False)\n",
    "    except Exception as e:\n",
    "        print(\"Global Gauss–Newton failed, retrying with smaller step:\", e)\n",
    "        x0_perturbed = x0_global + 1e-3 * np.random.randn(*x0_global.shape)\n",
    "        return gauss_newton_global(x0_perturbed, t_vec, R,\n",
    "                                   max_iters=200, tol=1e-8, eps=1e-6,\n",
    "                                   use_line_search=True,\n",
    "                                   verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c47fd8",
   "metadata": {},
   "source": [
    "\n",
    "### Final summary outputs\n",
    "The cells above already print per-week parameter estimates and SSE/RMSE for all three methods, along with the global fit metrics. Re-running the notebook from top to bottom will reproduce the calibration and the comparative diagnostics.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
